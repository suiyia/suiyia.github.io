{"meta":{"title":"菜鸟日常","subtitle":null,"description":null,"author":"Answer","url":"http://suiyia.github.io"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2019-10-15T15:07:47.109Z","updated":"2018-12-23T14:21:42.101Z","comments":false,"path":"/404.html","permalink":"http://suiyia.github.io//404.html","excerpt":"","text":""},{"title":"关于","date":"2019-09-19T09:11:15.000Z","updated":"2019-09-19T10:33:01.855Z","comments":true,"path":"about/index.html","permalink":"http://suiyia.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2019-10-15T15:07:47.109Z","updated":"2018-12-23T14:21:42.107Z","comments":false,"path":"books/index.html","permalink":"http://suiyia.github.io/books/index.html","excerpt":"","text":""},{"title":"callback","date":"2018-12-23T13:43:41.000Z","updated":"2018-12-23T13:43:41.903Z","comments":true,"path":"callback/index.html","permalink":"http://suiyia.github.io/callback/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-10-15T15:07:47.109Z","updated":"2018-12-23T14:21:42.109Z","comments":false,"path":"categories/index.html","permalink":"http://suiyia.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-10-15T15:07:47.112Z","updated":"2018-12-23T14:21:42.113Z","comments":false,"path":"tags/index.html","permalink":"http://suiyia.github.io/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-10-15T15:07:47.112Z","updated":"2018-12-23T14:21:42.109Z","comments":true,"path":"links/index.html","permalink":"http://suiyia.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2019-10-15T15:07:47.113Z","updated":"2018-12-23T14:21:42.112Z","comments":false,"path":"repository/index.html","permalink":"http://suiyia.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"Java 单例模式","slug":"Java-单例模式","date":"2019-10-18T07:47:00.000Z","updated":"2019-10-18T09:54:18.451Z","comments":true,"path":"2019/10/18/Java-单例模式/","link":"","permalink":"http://suiyia.github.io/2019/10/18/Java-单例模式/","excerpt":"","text":"介绍什么是单例模式：保证一个类仅有一个实例，并提供一个访问它的全局访问点解决什么问题：省略创建对象所花费的时间，不需要频繁创建对象，减轻 GC 压力单例模式实现：线程安全并发性能好可以延迟加载序列化/反序列化安全能抵御反射攻击饿汉式YY懒汉式-不加锁YY懒汉式-加锁YY双重检查 Double CheckYYY静态内部类YYY枚举YYYY懒汉式用的时候加载，上面只支持单线程，下面支持多线程，但是每次获取都要加锁，没必要。12345678910111213141516171819202122232425262728293031// public class Singleton &#123; private Singleton()&#123;&#125; private static Singleton singleton; public static Singleton getSingleton()&#123; if (singleton == null)&#123; singleton = new Singleton(); &#125; return singleton; &#125;&#125;// 加锁public class Singleton &#123; private Singleton()&#123;&#125; private static Singleton singleton; public static synchronized Singleton getSingleton()&#123; if (singleton == null)&#123; singleton = new Singleton(); &#125; return singleton; &#125;&#125;饿汉式在类加载时就完成了初始化，所以类加载较慢，但获取对象的速度快。通过类加载机制保证单例，但是如果代码中有其它方式导致类加载，就不满足单例1234567891011public class Singleton &#123; public static Singleton singleton = new Singleton(); private Singleton()&#123;&#125; public static getSingleton() &#123; return singleton; &#125; &#125;双重校验1234567891011121314151617public class Singleton &#123; private Singleton()&#123;&#125; public static volatile Singleton singleton; public static getSingleton()&#123; if (singleton == null)&#123; synchronized(Singleton.class)&#123; if (singleton == null)&#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125;静态内部类Singleton 类被装载了，instance 不一定被初始化只有通过显式调用 getInstance 方法时，才会显式装载 SingletonHolder 类这种方式只适用于静态域的情况1234567891011121314public class Singleton &#123; private Singleton ()&#123;&#125; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; public static final Singleton getSingleton()&#123; return SingletonHolder.INSTANCE; &#125; &#125;枚举123456public enum Singleton &#123; INSTANCE; public void doSomeThing() &#123; &#125; &#125;参考单例模式面试官所认为的单例模式","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://suiyia.github.io/tags/设计模式/"}]},{"title":"ConcurrentHashMap 源码学习","slug":"ConcurrentHashMap-源码学习","date":"2019-10-16T08:37:00.000Z","updated":"2019-10-18T07:47:02.053Z","comments":true,"path":"2019/10/16/ConcurrentHashMap-源码学习/","link":"","permalink":"http://suiyia.github.io/2019/10/16/ConcurrentHashMap-源码学习/","excerpt":"","text":"本文 java version “1.8.0_221”结构与 HashMap 类似，使用数组 + 链表 + 红黑树存储键值对属性字段transient volatile Node&lt;K,V&gt;[] table; // 存放 bin，第一次插入数据时候进行初始化，长度为 2 的倍数private static final int MIN_TRANSFER_STRIDE = 16 // 扩容线程每次最少要迁移16 个 hash 桶，在扩容中，参与的单个线程允许处理的最少 table 桶首节点个数，虽然适当添加线程，会使得整个扩容过程变快，但需要考虑多线程内存同时分配的问题private transient volatile int sizeCtl;默认为 0-1 表示正在初始化-(1+number) 表示有 number 个线程同时在扩容，必须竞争到这个共享变量，才能进行初始化或者扩容。正数， table 中元素数量阈值，超过这个阈值就会扩容static final int MOVED = -1; // hash for forwarding nodesForwardingNode，在扩容时使用，如果 index 处 hash 值为 -1，表示正在扩容。static final int TREEBIN = -2; // hash for roots of treesstatic final int RESERVED = -3; // hash for transient reservationsstatic final int HASH_BITS = 0x7fffffff; // usable bits of normal哈希桶 Table 初始化根据共享变量 sizeCtl 的值来决定是否由当前线程执行初始化操作（单线程进行初始化）sizeCtl 为正数时，表示 table 的阈值（= 0.75*n），元素个数超过这个值将会扩容。123456789101112131415161718192021222324252627private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; // 如果共享变量 sizeCtl &lt; 0，说明有其它线程正在初始化或者扩容，让出 CPU，让其它线程先执行完 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin // else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; // 再判断 table 是否为空 if ((tab = table) == null || tab.length == 0) &#123; // sc = sizeCtl &gt; 0 表示已经初始化，否则使用默认容量 16。 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // sc = 0.75*n，sc 表示阈值 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125;key 对应到哈希桶的过程12345static final int spread(int h) &#123; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;&#125;index = spread(key) &amp; (length - 1)hash 过程与 HashMap 类似，只是多了与 HASH_BITS 进行位运算HASH_BITS 除了首位是 0，剩下的都是 1，按位与，得正数(首位为0)。就是为了让上面的 hash 值为正数get 方法key，value 都不能为 null，key 为 null 时抛出 NullPointerException将 key 进行 hash 然后找到数组位置处的索引 index若 index == key，直接返回 index 处元素若 index 处的 hash 值小于 0，进一步调用 Node 子类的 find 方法index 处的 hash 值不小于 0，遍历查找12345678910111213141516171819202122static final int TREEBIN = -2; // hash for roots of treespublic V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 如果找到这个节点，直接返回 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // 如果 hash 值小于 0，调用 Node 的查找方法，Node 可以为链表或树 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125;put 方法table 为 null 或者 tab.size = 0，进行 resize。key 进行 hash 之后取模得到的索引位置，若在桶的位置元素为 null，那么直接插入元素。桶位置元素不为 null，那么进行比较判断 key 是否相同：如果 key 相同，e 保存该节点如果 key 不同，如果该是红黑树节点，那么执行红黑树的 put 方法；如果是链表节点，执行链表遍历操作，找到对应的节点并用 e 保存，如果链表长度大于 &gt;=7，就将链表转为红黑树Node e 保存找到的节点，如果没有找到返回 null如果 size 超过阈值，进行扩容1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; // key value 均不能为 null if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; // 获取当前 table，进入死循环，直至插入成功 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 为空需要进行初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 索引所在位置没有元素，通过 casTabAt 方法插入元素并跳出循环 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null)))&#123; break; // no lock when adding to empty bin &#125; &#125; // 索引位置处 hash = -1，表示其它线程正在扩容，helpTransfer 将帮助扩容，且元素赋值到扩容后的位置 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); // 该位置处节点为普通节点，锁住该链表头结点并在尾部添加节点 else &#123; V oldVal = null; synchronized (f) &#123; // 加锁之后再判断索引位置处 key 是否相同 if (tabAt(tab, i) == f) &#123; // hash &gt;= 0，通过链表遍历方式找到并替换节点 if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) // 进行替换 e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; // 链表尾部插入节点 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // index 处索引小于 0 （hash = -2 TREEBIN），并且是树节点，执行树的插入方法 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; // binCount != 0 说明向链表或者红黑树中添加或修改一个节点成功 // binCount == 0 说明 put 操作将一个新节点添加成为某个桶的首节点 if (binCount != 0) &#123; // &gt;= 8 就转为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); // oldVal != null 说明此次操作是修改操作，直接返回旧值，无需下面扩容检查 if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 判断是否需要扩容 addCount(1L, binCount); return null;&#125;size()baseCount 记录元素个数，通过 addCount 更新 baseCount，当更新失败时，addCount 中的 fullCount 会更新 counterCells元素个数 = baseCount + counterCells.length123456789101112131415161718public int size() &#123; long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n);&#125;final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125;扩容方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189// 返回表长度 n 的标志位static final int resizeStamp(int n) &#123; return Integer.numberOfLeadingZeros(n) | (1 &lt;&lt; (RESIZE_STAMP_BITS - 1));&#125;// 帮助扩容final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; // tab 不为 null，传进来的节点是 ForwardingNode，并且 ForwardingNode 下一个 tab 不为 null if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; // 生成标志位 rs int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; // 如果 sizeCtl 无符号右移 16 位与上面标志位不同 // 或者 sizeCtl == rs + 1 （扩容结束了，不再有线程进行扩容） // 或者 sizeCtl == rs + 65535 （如果达到最大帮助线程的数量，即 65535） // 或者转移下标正在调整 （扩容结束） // 结束循环 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; // 以上情况不满足， sizeCtl++ ，增加一个线程进行扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; // 复制或者移动 bins 里面的 Node 到新的 table transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table;&#125;// 移动或者复制 Node 到新的 tableprivate final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; // 计算单个线程允许处理的最少 table 桶首节点个数，不能小于 16 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range // 如果刚开始扩容，就初始化 nextTab if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; // transferIndex 指向最后一个桶，方便从后向前遍历 transferIndex = n; &#125; int nextn = nextTab.length; // fwd 作为标记，标记那些已经完成迁移的桶 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab // i 指向当前桶，bound 指向当前线程需要处理的桶结点的区间下限 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; // transferIndex 本来指向最后一个桶，小于等于 0 说明处理完成 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; // 更新 transferIndex，处理的桶区间为 (nextBound,nextIndex) else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; // 当前线程任务处理完成 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; // 待迁移的桶为 null，在此位置添加 ForwardingNode 标记该桶已经处理过 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 该桶已经处理过 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; // 锁住该桶 synchronized (f) &#123; // 再判断下桶有没有发生变化 if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123; int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; // 整个 for 循环为了找到整个桶中最后连续的 fh &amp; n 不变的结点 for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; // 如果 fh&amp;n 不变的链表的 runbit 都是 0，则 nextTab[i] 内元素 ln 前逆序，ln 及其之后顺序 // 否则，nextTab[i+n]内元素全部相对原table逆序 // 这是通过一个节点一个节点的往 nextTab 添加 for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; // 把两条链表整体迁移到 nextTab 中 setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); // 将原桶标识位已经处理 setTabAt(tab, i, fwd); advance = true; &#125; // 红黑树的复制算法 else if (f instanceof TreeBin) &#123; TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125;sizeCtl == rs + 1 扩容结束了，不再有线程进行扩容，这个判断可以在 addCount 方法中找到答案：默认第一个线程设置 sc == rs 左移 16 位 + 2，当第一个线程结束扩容了，就会将 sc 减一。这个时候，sc 就等于 rs + 1。如果 sizeCtl == 标识符 + 1 ，说明库容结束了，没有必要再扩容了。博客参考并发编程——ConcurrentHashMap#helpTransfer() 分析为并发而生的 ConcurrentHashMap（Java 8）https://www.iteye.com/blog/wujiu-2378812","categories":[],"tags":[{"name":"Java 集合","slug":"Java-集合","permalink":"http://suiyia.github.io/tags/Java-集合/"}]},{"title":"HashMap 源码学习","slug":"HashMap-源码学习","date":"2019-10-15T14:07:00.000Z","updated":"2019-10-16T08:34:04.155Z","comments":true,"path":"2019/10/15/HashMap-源码学习/","link":"","permalink":"http://suiyia.github.io/2019/10/15/HashMap-源码学习/","excerpt":"","text":"本文 java version “1.8.0_221”属性字段static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 初始默认容量大小，如果指定容量，容量必须是 2 的倍数static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 最大的容量大小 1*2^30=1073741824 ，如果指定容量，容量必须是 2 的倍数static final float DEFAULT_LOAD_FACTOR = 0.75f; // 默认负载因子static final int TREEIFY_THRESHOLD = 8; // 超过 8 就变为 红黑树static final int UNTREEIFY_THRESHOLD = 6; // 小于 6 变为链表transient Node&lt;K,V&gt;[] table; // 存放元素的哈希桶数组transient int size; // 当前 Map 中 键值对数量final float loadFactor; // 负载因子int threshold; // 当前 Map 能容纳的最大键值对数量，threshold = length * Load factortransient int modCount; // 结构性修改的次数，用于 fail-fast 机制key 对应到哈希桶的过程123456static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;index = hash(key) &amp; (length - 1)若 key == null，放到数组第一位key != null，调用 Object.hashCode() 方法将 key 进行 hash 得到 h将 h 与 h 右移 16 位后的数值进行异或得到一个 hash 值将第 3 步得到 hash 值与数组长度减一进行与运算，得到 key 在哈希桶的索引位置。第 4 步非常巧妙，它通过 h&amp;(table.length -1)来得到该对象的保存位，而 HashMap 底层数组的长度总是2的n次方，这是 HashMap 在速度上的优化。当 length 总是 2 的 n 次方时，h&amp; (length-1)运算等价于对 length 取模，也就是h%length，但是 &amp; 比 % 具有更高的效率。get 方法put 方法支持，key、value 都为 null，并且是 尾插法get 方法返回 null，有两种情况：一是不包含这个键值对，二是该键值对的键 key 对应的 value 就是 null，可以通过 containsKey 方法判断 Map 是否包含该 key12345678910111213141516171819202122232425262728public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 找到 hash 值一样的桶 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) // 如果第一个元素 key 相同，返回这个 Node return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 如果是树节点，那么去树里面找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 在链表中找 return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125;static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;put 方法table 为 null 或者 tab.size = 0，进行 resize。key 进行 hash 之后取模得到的索引位置，若在桶的位置元素为 null，那么直接插入元素。桶位置元素不为 null，那么进行比较判断 key 是否相同：如果 key 相同，e 保存该节点如果 key 不同，如果该是红黑树节点，那么执行红黑树的 put 方法；如果是链表节点，执行链表遍历操作，找到对应的节点并用 e 保存，如果链表长度大于 &gt;=7，就将链表转为红黑树Node e 保存找到的节点，如果没有找到返回 null如果 size 超过阈值，进行扩容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 如果 table 的在（n-1）&amp;hash 的值是 null，就新建一个节点插入在该位置 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 表示该索引位置有值 else &#123; Node&lt;K,V&gt; e; K k; // 如果 key 相等，那么 Node e 保存原来的值用于替换 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))&#123; e = p; // 如果 key 最终不等，而且是树节点，执行红黑树的 put 方法 &#125; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 如果 key 最终不等，而且是链表节点，执行链表的 put 方法 else &#123; for (int binCount = 0; ; ++binCount) &#123; // 如果指针为空就挂在后面 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st // 链表数量 &gt;= 7 就转为红黑树 treeifyBin(tab, hash); break; &#125; // 链表上面有相同的 key 的元素，那么 e 保存原来的值 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 最终 Map 中有该元素，那么进行 value 替换 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; // 结构修改次数加 1 ++modCount; // 如果新增一个元素后容量大于阈值，进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125;resize 方法扩容是 2 倍的倍数进行扩容扩容后，换一个更大的数组重新映射，元素的位置要么是在原位置，要么是在原位置再移动 2 次幂的位置。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 如果原来的桶长度已经超过最大阈值，那么数组扩大到 2^31 -1 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; // 如果原来桶长度扩大 2 倍后还是小于最大阈值，那么新阈值为原来阈值的 2 倍 &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY)&#123; newThr = oldThr &lt;&lt; 1; // double threshold &#125; &#125; else if (oldThr &gt; 0)&#123; // initial capacity was placed in threshold newCap = oldThr;// &#125; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 链表优化重hash的代码块 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 原索引 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; // 原索引+oldCap else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); // 原索引放到bucket里 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 原索引+oldCap放到bucket里 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125;博客参考HashMap的底层实现Java8的HashMap详解（存储结构，功能实现，扩容优化，线程安全，遍历方法），是下面的总结Java 8系列之重新认识HashMap","categories":[],"tags":[{"name":"Java 集合","slug":"Java-集合","permalink":"http://suiyia.github.io/tags/Java-集合/"}]},{"title":"Java 多线程学习——常用类与方法","slug":"Java-多线程学习——常用类与方法","date":"2019-10-14T15:04:00.000Z","updated":"2019-10-15T07:15:35.674Z","comments":true,"path":"2019/10/14/Java-多线程学习——常用类与方法/","link":"","permalink":"http://suiyia.github.io/2019/10/14/Java-多线程学习——常用类与方法/","excerpt":"","text":"ThreadLocalJava 中的 ThreadLocal 类允许我们创建只能被同一个线程读写的变量。因此，如果一段代码含有一个 ThreadLocal 变量的引用，即使两个线程同时执行这段代码，它们也无法访问到对方的 ThreadLocal 变量。1private ThreadLocal myThreadLocal = new ThreadLocal();Java进阶（七）正确理解Thread Local的原理与适用场景volatile一旦一个共享变量（类的成员变量、类的静态成员变量）被 volatile 修饰之后，那么就具备了两层语义：1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。2）禁止进行指令重排序。Java 内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。Java并发编程：volatile关键字解析ReentrantLockReentrantLock 重入锁，是实现 Lock 接口的一个类，表示能够对共享资源能够重复加锁，即当前线程获取该锁再次获取不会被阻塞。ReentrantLock还支持公平锁和非公平锁两种方式。Java并发学习之ReentrantLock的工作原理及使用姿势Java并发之ReentrantLock详解ReentrantLock 与 Synchronized 区别ReentrantLock 显示的获得、释放锁，synchronized 隐式获得释放锁ReentrantLock 可响应中断、可轮回，synchronized 是不可以响应中断的，为处理锁的不可用性提供了更高的灵活性ReentrantLock 是 API 级别的，synchronized 是 JVM 级别的ReentrantLock 可以实现公平锁ReentrantLock 通过 Condition 可以绑定多个条件底层实现不一样， synchronized 是同步阻塞，使用的是悲观并发策略，lock 是同步非阻塞，采用的是乐观并发策略Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言实现。synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock() 去释放锁，则很可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁。Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，等待的线程会一直等待下去，不能够响应中断。通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。Lock 可以提高多个线程进行读操作的效率，既就是实现读写锁等。BlockingQueue阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。方法\\处理方式抛出异常返回特殊值一直阻塞超时退出插入方法add(e)offer(e)put(e)offer(e,time,unit)移除方法remove()poll()take()poll(time,unit)检查方法element()peek()不可用不可用抛出异常：是指当阻塞队列满时候，再往队列里插入元素，会抛出 IllegalStateException(“Queue full”) 异常。当队列为空时，从队列里获取元素时会抛出 NoSuchElementException 异常 。返回特殊值：插入方法会返回是否成功，成功则返回 true。移除方法，则是从队列里拿出一个元素，如果没有则返回 null一直阻塞：当阻塞队列满时，如果生产者线程往队列里 put 元素，队列会一直阻塞生产者线程，直到拿到数据，或者响应中断退出。当队列空时，消费者线程试图从队列里 take 元素，队列也会阻塞消费者线程，直到队列可用。超时退出：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。聊聊并发（七）——Java 中的阻塞队列","categories":[],"tags":[{"name":"Java 多线程","slug":"Java-多线程","permalink":"http://suiyia.github.io/tags/Java-多线程/"}]},{"title":"Java 多线程学习——Synchronize","slug":"Java-多线程学习——Synchronize","date":"2019-10-14T12:00:00.000Z","updated":"2019-10-14T15:05:05.972Z","comments":true,"path":"2019/10/14/Java-多线程学习——Synchronize/","link":"","permalink":"http://suiyia.github.io/2019/10/14/Java-多线程学习——Synchronize/","excerpt":"","text":"多线程虽然能够一定程度上解决高并发请求的问题，但是利用多线程进行开发，首先要保证的就是线程安全。线程安全：无论在单线程还是多线程的情况下，业务代码输出结果不变。同步：要实现线程安全，就需要同步，即依靠认为的调度和控制，使得业务代码按照人们意向的方向进行。关于 Synchronized 的一些概念对象锁：在 Java 中，每个对象都会有一个 monitor 对象，这个对象其实就是 Java 对象的锁，通常会被称为“内置锁”或“对象锁”。类的对象可以有多个，所以每个对象有其独立的对象锁，互不干扰。类锁：在 Java 中，针对每个类也有一个锁，可以称为“类锁”，类锁实际上是通过对象锁实现的，即类的 Class 对象锁。每个类只有一个 Class 对象，所以每个类只有一个类锁。Synchronized 用法this、object（对象锁）类.class（类锁）方法（对象锁）静态方法（类锁）生产者消费者java多线程同步(wait、notify)生产者消费者简单示例总结无论 synchronized 关键字加在方法上还是对象上，如果它作用的对象是非静态的，则它取得的锁是对象；如果synchronized作用的对象是一个静态方法或一个类，则它取得的锁是对类，该类所有的对象同一把锁。同一个类的不同对象的对象锁互不干扰对象锁和类锁是独立的，互不干扰synchronized 关键字不能继承，父类中的 synchronized 修饰方法，子类在覆盖该方法时，默认情况下不是同步的，必须显示的使用 synchronized 关键字修饰才行。关键字 synchronize 拥有锁重入的功能，也就是在使用 synchronize 时，当一个线程的得到了一个对象的锁后，再次请求此对象是可以再次得到该对象的锁。博客参考Java 之 synchronized 详解Java中Synchronized的用法","categories":[],"tags":[{"name":"Java 多线程","slug":"Java-多线程","permalink":"http://suiyia.github.io/tags/Java-多线程/"}]},{"title":"Java 多线程学习——基础概念","slug":"Java多线程——基础概念","date":"2019-10-14T02:52:00.000Z","updated":"2019-10-14T15:02:56.167Z","comments":true,"path":"2019/10/14/Java多线程——基础概念/","link":"","permalink":"http://suiyia.github.io/2019/10/14/Java多线程——基础概念/","excerpt":"","text":"并行与并发解释一：并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔发生（注意的是时间间隔，间隔是有大小的）。解释二：并行是在不同实体上的多个事件，并发是在同一实体上的多个事件。解释三：在一台处理器上同时处理多个任务，在多台处理器上同时处理多个任务。如 hadoop 分布式集群这里另外再用一张经常用的图来解释并发与并行之间的关系并发就像只有一台咖啡机能制造咖啡（单核 CPU）的店铺，然而有序列 A 和序列 B 两队人在排队，在一个时间段内（咖啡机可能造出多杯咖啡），序列 A 和序列 B的人可能都会领取到咖啡，在这个时间段内多个人领取到咖啡这个过程称为 并发，这个时间段类似于多个 CPU 时间片，一个 CPU 时间片执行一个任务。并行就像有两台咖啡机的店铺，然后在同一个时刻，都会有两个人领取到咖啡，这样的过程称为 并行。Java 多线程实现方式平时所说的多线程，其实就是并发知识的底层实现，Java 现在有多种多线程的实现方式，最基础的两种方式是：方式一：继承 Thread 类（一般不用，继承会把类的特性限制太死）12345678910public class MyThread extends Thread &#123; public void run() &#123; System.out.println(&quot;MyThread.run()&quot;); &#125; &#125; MyThread myThread1 = new MyThread(); MyThread myThread2 = new MyThread(); myThread1.start(); myThread2.start();方式二：实现 Runnable 接口12345678910public class ThreadB implements Runnable &#123; @Override public void run() &#123; System.out.println(&quot;ThreadB&quot;); &#125;&#125;Thread thread = new Thread(new ThreadB());thread.start();还有其它实现方式，如实现 Callable 接口、Future 等，参考 JAVA多线程实现的四种方式这里 run() 方法内的逻辑表示线程执行的业务逻辑，而让线程启动的方法是 start()start() 方法，即启动线程的方法，通过了解 start() 源码，执行 start 时，会有两个线程并发执行，当前线程去调用 start() 方法，另外一个线程会调 run() 方法开始具体的业务逻辑。需要注意的是，一个线程不能被启动多次，只有当它业务逻辑执行完成之时，才会启动下一次，否则会抛出 IllegalThreadStateException 异常。线程的六种状态根据 java.lang.Thread.State 枚举类源码可知，有 6 种不同的线程状态。These states are virtual machine states which do not reflect any operating system thread states.NEW（新建）：仅定义了一个线程对象，还未调用它的 start() 方法。Thread state for a thread which has not yet started.RUNNABLE（可运行）：调用了线程的 start 方法，已经被 JVM 执行，但还在等待系统其它资源，如 CPU 时间片、I/O 等，根据操作系统知识可进一步将可运行状态细分为就绪、运行中两种状态（Java 并没有进一步细分）。Thread state for a runnable thread. A thread in the runnable state is executing in the Java virtual machine but it may be waiting for other resources from the operating system such as processor.就绪：调用了 start 方法，但没有得到 CPU 时间片的状态运行中：得到了 CPU 时间片的状态，正在执行BLOCKED（阻塞）：线程等待 monitor lock 的状态，只有得到了这个对象锁之后，状态才会由阻塞变为就绪。Thread state for a thread blocked waiting for a monitor lock.A thread in the blocked state is waiting for a monitor lock to enter a synchronized block/method or reenter a synchronized block/method after calling {@link Object#wait() Object.wait}.等待阻塞：运行的线程执行 o.wait() 方法，JVM 会把该线程放入等待队列(waitting queue)中同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则 JVM 会把该线程放入锁池(lock pool)中其他阻塞：运行的线程执行 Thread.sleep(long ms) 或t.join() 方法，或者发出了 I/O 请求时，JVM 会把该线程置为阻塞状态，当 sleep() 状态超时、join() 等待线程终止或者超时、或者 I/O 处理完毕时，线程重新转入可运行(runnable)状态WAITING（等待）：A thread in the waiting state is waiting for another thread to perform a particular action.等待另一个线程的特定操作的状态，等待被其他线程唤醒等待的过程是主动等待的，而阻塞是得不到对象锁而被动阻塞住当线程拿到锁之后，调用相应锁对象的 wait()、join()、继承 LockSupport 类的 park() ，调用其中的方法线程就会处于这个状态。TIMED_WAITING（有限期等待或超时等待）：Thread state for a waiting thread with a specified waiting time.等待另一个线程执行指定等待时间的操作的线程处于此状态等待另一个线程特定时间，时间过后会自动唤醒线程执行 sleep（）、wait（long）、join（long）、LockSupport.parkNanos 、LockSupport.parkUntil 方法时会处于这种状态TERMINATED（终止）：线程业务逻辑执行完成退出的状态Thread state for a terminated thread.The thread has completed execution.线程具有的方法主要讲解它的方法以及状态的切换、锁持有状态Thread.sleep(long millis)，一定是当前线程调用此方法，线程进入 TIME_WAITING 状态，但不释放对象锁，millis 后线程自动苏醒进入就绪状态。作用：给其它线程执行机会的最佳方式。Thread.yield()，一定是当前线程调用此方法，当前线程放弃获取的 cpu 时间片，由运行状态变会就绪状态，让 OS 再次选择线程。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证 yield() 达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。Thread.yield() 不会导致阻塞。t.join()/t.join(long millis)，当前线程里调用其它线程 t 的 join 方法，当前线程进入 TIME_WAITING 状态，当前线程不释放已经持有的对象锁。线程 t 执行完毕或者 millis 时间到，当前线程进入就绪状态。obj.wait()，当前线程调用对象的 wait() 方法，当前线程释放对象锁，进入等待队列。依靠 notify()/notifyAll() 唤醒或者 wait(long timeout) timeout 时间到自动唤醒。obj.notify() 唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll() 唤醒在此对象监视器上等待的所有线程。终止线程的 4 种方式正常结束退出标识：有些线程需要长时间的运行，只有在外部某些条件满足的情况下，才能关闭这些线程Interrupt() 方法线程处于阻塞状态：调用 interrupt() 方法会抛出异常，此时要退出线程必须 catch 异常，并使用 break 方法退出。线程不处于阻塞状态：使用 isInterrupted() 判断线程的中断标志来退出循环，当使用 interrupt() 方法时，中断标志就会置 truestop 方法：thread.stop() 调用之后，创建子线程的线程就会抛出 ThreadDeatherror 的错误，并且会释放子线程所持有的所有锁。一般任何进行加锁的代码块，都是为了保护数据的一致性，如果在调用 thread.stop() 后导致了该线程所持有的所有锁的突然释放(不可控制)，那么被保护数据就有可能呈现不一致性线程池及线程池种类newCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。Java 中推荐手动创建线程池的方式：ThreadPoolExecutor123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125;corePoolSize：核心线程数量，当有新任务在execute()方法提交时，会执行以下判断：如果运行的线程少于 corePoolSize，则创建新线程来处理任务，即使线程池中的其他线程是空闲的；如果线程池中的线程数量大于等于 corePoolSize 且小于 maximumPoolSize，则只有当workQueue满时才创建新的线程去处理任务；如果设置的corePoolSize 和 maximumPoolSize相同，则创建的线程池的大小是固定的，这时如果有新任务提交，若workQueue未满，则将请求放入workQueue中，等待有空闲的线程去从workQueue中取任务并处理；如果运行的线程数量大于等于maximumPoolSize，这时如果workQueue已经满了，则通过handler所指定的策略来处理任务；所以，任务提交时，判断的顺序为 corePoolSize –&gt; workQueue –&gt; maximumPoolSize。maximumPoolSize：最大线程数量；workQueue：等待队列，当任务提交时，如果线程池中的线程数量大于等于corePoolSize的时候，把该任务封装成一个Worker对象放入等待队列；workQueue：保存等待执行的任务的阻塞队列，当提交一个新的任务到线程池以后, 线程池会根据当前线程池中正在运行着的线程的数量来决定对该任务的处理方式，主要有以下几种处理方式:直接切换：这种方式常用的队列是SynchronousQueue，但现在还没有研究过该队列，这里暂时还没法介绍；使用无界队列：一般使用基于链表的阻塞队列LinkedBlockingQueue。如果使用这种方式，那么线程池中能够创建的最大线程数就是 corePoolSize，而 maximumPoolSize 就不会起作用了（后面也会说到）。当线程池中所有的核心线程都是 RUNNING 状态时，这时一个新的任务提交就会放入等待队列中。使用有界队列：一般使用 ArrayBlockingQueue。使用该方式可以将线程池的最大线程数量限制为 maximumPoolSize，这样能够降低资源的消耗，但同时这种方式也使得线程池对线程的调度变得更困难，因为线程池和队列的容量都是有限的值，所以要想使线程池处理任务的吞吐率达到一个相对合理的范围，又想使线程调度相对简单，并且还要尽可能的降低线程池对资源的消耗，就需要合理的设置这两个数量。如果要想降低系统资源的消耗（包括CPU的使用率，操作系统资源的消耗，上下文环境切换的开销等）, 可以设置较大的队列容量和较小的线程池容量, 但这样也会降低线程处理任务的吞吐量。如果提交的任务经常发生阻塞，那么可以考虑通过调用 setMaximumPoolSize() 方法来重新设定线程池的容量。如果队列的容量设置的较小，通常需要将线程池的容量设置大一点，这样CPU的使用率会相对的高一些。但如果线程池的容量设置的过大，则在提交的任务数量太多的情况下，并发量会增加，那么线程之间的调度就是一个要考虑的问题，因为这样反而有可能降低处理任务的吞吐量。keepAliveTime：线程池维护线程所允许的空闲时间。当线程池中的线程数量大于corePoolSize的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了keepAliveTime；threadFactory：它是ThreadFactory类型的变量，用来创建新线程。默认使用Executors.defaultThreadFactory() 来创建线程。使用默认的ThreadFactory来创建线程时，会使新创建的线程具有相同的NORM_PRIORITY优先级并且是非守护线程，同时也设置了线程的名称。handler：它是RejectedExecutionHandler类型的变量，表示线程池的饱和策略。如果阻塞队列满了并且没有空闲的线程，这时如果继续提交任务，就需要采取一种策略处理该任务。线程池提供了4种策略：AbortPolicy：直接抛出异常，这是默认策略；CallerRunsPolicy：用调用者所在的线程来执行任务；DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；DiscardPolicy：直接丢弃任务，但是不抛出异常；深入理解 Java 线程池：ThreadPoolExecutor博客参考并发和并行有什么区别？Java语言定义的线程状态分析Java线程的6种状态及切换(透彻讲解)Java中的多线程你只要看这一篇就够了","categories":[],"tags":[{"name":"Java多线程","slug":"Java多线程","permalink":"http://suiyia.github.io/tags/Java多线程/"}]},{"title":"Java 网络请求方法整理基于 JDK 1.8","slug":"Java-网络请求方法整理基于-JDK-1-8","date":"2019-10-13T07:20:00.000Z","updated":"2019-10-13T07:20:51.266Z","comments":true,"path":"2019/10/13/Java-网络请求方法整理基于-JDK-1-8/","link":"","permalink":"http://suiyia.github.io/2019/10/13/Java-网络请求方法整理基于-JDK-1-8/","excerpt":"","text":"介绍写代码过程中发现自己对 Java 的一些 HTTP 请求方法不是很熟悉，也没有一个全局的概念框架，网上的一些博客使用的方法已经被 JDK 所抛弃。于是简单整理下 Java 中常用的 HTTP 请求方法，以及它们的适用场景等，方便自己以后使用，本文基于 JDK 1.8。这篇文章的作用很简单：了解 Java 开发中常用的 HTTP 请求方法了解这些方法的适用场景和注意事项使用最新的方法，抛弃被添加 @Deprecated 注解的方法1. 常用的 HTTP 请求方法Socket：又称套接字，它工作在传输层，是所有应用层 HTTP 请求的底层实现。通过 ip 地址 + 端口号 即可实现网络通信HttpURLConnection：继承了抽象类 URLConnection，源码中它定义了一些网络请求的返回码；也能够对 HTTP 请求做一些参数调整，例如使用 POST 请求、使用代理HttpClient：是 Apache 下的子项目，使用时需要引入第三方 org.apache.httpcomponents.httpclient.jar 包，它对 HTTP 请求的一些方法封装的更多，造好的轮子，使用也更加方便2. 各个 HTTP 请求方法示例Socket12345678910111213141516171819202122232425262728public static void SocketDemo(URL url,String content)&#123; try &#123; url = new URL(\"https://www.apiopen.top\"); String path = \"/weatherApi?city=%E6%AD%A6%E6%B1%89\"; String host = url.getHost(); int port = 80; // 请求的 端口号 Socket socket = new Socket(host,port); // 需要添加方法头，不然无法正确运行 OutputStreamWriter osw = new OutputStreamWriter(socket.getOutputStream(),\"utf-8\"); osw.write(\"GET \" + path + \" HTTP/1.1\\r\\n\"); osw.write(\"Host: \" + host + \" \\r\\n\"); osw.write(\"Connection: Keep-Alive\\r\\n\"); osw.write(\"Content-Type: application/x-www-form-urlencoded; charset=utf-8 \\r\\n\"); osw.write(\"\\r\\n\"); // 获取响应结果并输出 BufferedReader reader = new BufferedReader(new InputStreamReader(socket.getInputStream())); String readLine; StringBuffer stringBuffer = new StringBuffer(); while ((readLine = reader.readLine()) != null) &#123; stringBuffer.append(readLine); &#125; System.out.println(stringBuffer.toString()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125;HttpURLConnection1234567891011121314151617181920212223242526public static void HttpURLConnection(URL url, String content) &#123; try &#123; HttpURLConnection connection = (HttpURLConnection) url.openConnection(); connection.setDoInput(true); // 表示 getOutput() 的时候能起作用 connection.setDoOutput(true); // 表示 getInput() 的时候能起作用 connection.setUseCaches(false); // 不使用缓存 connection.setRequestMethod(\"POST\"); // POST 请求 OutputStream outputStream = connection.getOutputStream(); outputStream.write(content.getBytes(\"UTF-8\")); outputStream.close(); // 获取响应结果并输出 BufferedReader reader = new BufferedReader(new InputStreamReader(connection.getInputStream())); String readLine; StringBuffer stringBuffer = new StringBuffer(); while ((readLine = reader.readLine()) != null) &#123; stringBuffer.append(readLine); &#125; System.out.println(stringBuffer.toString()); &#125; catch (MalformedURLException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125;HttpClient12345678910public static void HTTPClient(URL url,String content)&#123; try &#123; HttpClient client = HttpClients.createDefault(); HttpPost post = new HttpPost(url.toString()); // 执行 POST 请求，GET 请求有 HttpGet CloseableHttpResponse response = (CloseableHttpResponse) client.execute(post); // 得到返回结果 System.out.println(EntityUtils.toString(response.getEntity())); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125;Main 方法123456789101112public static void main(String[] args) &#123; try &#123; URL url = new URL(\"https://www.apiopen.top/weatherApi?city=%E6%AD%A6%E6%B1%89\"); String content = \"123\"; HttpURLConnection(url, content); HTTPClient(url,content); SocketDemo(url,content); &#125; catch (MalformedURLException e) &#123; e.printStackTrace(); &#125;&#125;3. 总结上面各个方法适用场景上面三个方法返回结果都是一样的，看代码量都知道使用哪个好，时间紧迫的时候直接用别人造好的轮子很有必要但是想提升内功，建议先学习 Socket 通信等知识，对自己以后的提升帮助会很大，机会总是留给有意无意有准备的人","categories":[],"tags":[]},{"title":"本地运行 Kafka 与 Zookeeper ","slug":"本地运行-Kafka-与-Zookeeper","date":"2019-10-13T07:17:00.000Z","updated":"2019-10-13T07:18:56.975Z","comments":true,"path":"2019/10/13/本地运行-Kafka-与-Zookeeper/","link":"","permalink":"http://suiyia.github.io/2019/10/13/本地运行-Kafka-与-Zookeeper/","excerpt":"","text":"介绍本地运行 kafka，运行生产消费实例。Kafka 是一个分布式发布-订阅消息系统。Zookeeper 是一个高性能分布式应用协调服务。他们之间的关系 参考环境安装安装 Zookeeper参考配置地址注意 环境变量 配置，配置文件重命名启动方式：Windows 平台直接点击 zkServer.cmd，Linux 平台 ./zkServer.sh startZookeeper 可视化（可选）：安装 zk ui，先用 maven 打包，再修改配置文件，再启动123456#vim config.cfgserverPort=9090 #指定端口zkServer=localhost:2181sessionTimeout=300000java -jar target/zkui-2.0-SNAPSHOT-jar-with-dependencies.jar &amp;安装 Kafka下载地址，下载二进制文件，即 Binary downloadsconfig/server.properties 配置，参考123listeners=PLAINTEXT://:9092advertised.listeners=PLAINTEXT://192.168.2.104:9092 # 对应 kafka 运行的机器的 ip 地址zookeeper.connect=localhost:2181运行调试启动 Kafka，Windows 进入 C:\\canal\\kafka_2.11-2.0.1\\bin\\windows 目录下1kafka-server-start.bat ../../config/server.properties新建 topic 为 testDemo 的 Producer，bin\\windows 目录下，在该窗口输入任意字符12kafka-console-producer.bat --broker-list localhost:9092 --topic testDemo&gt; 123新建 Consumer，接收 topic 为 testDemo 的消息，bin\\windows 目录下1kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic testDemo运行参考查看这个 kafka 服务下所有的 topic1kafka-topics.bat --list --zookeeper 127.0.0.1:2181相关问题consumer zookeeper is not a recognized option办法：版本问题，使用 –bootstrap-server 代替 –zookeeper-server","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://suiyia.github.io/tags/kafka/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"http://suiyia.github.io/tags/Zookeeper/"}]},{"title":"Java 基本数据类型与包装类","slug":"Java-基本数据类型与包装类","date":"2019-10-13T07:15:00.000Z","updated":"2019-10-13T07:16:35.451Z","comments":true,"path":"2019/10/13/Java-基本数据类型与包装类/","link":"","permalink":"http://suiyia.github.io/2019/10/13/Java-基本数据类型与包装类/","excerpt":"","text":"介绍本文主要介绍基本数据类型相关概念、自动拆装箱机制和可能遇到的问题阐述。基本概念1. 8 种基本数据类型，具体可以分为下面 3 类：数值型整数型：byte、short、int、long浮点型：float、double字符型：char布尔型：boolean基本数据类型长度默认值byte字节、1 byte 就是 1 个字节，8 位二进制，-128 ~ 1270short2 字节，16 位，-2^15 ~ 2^15 - 10int4 字节，32 位，-2^31 ~ 2^31 - 10long8 字节，64 位，-2^63 ~ 2^63 -10float4 字节，32 位；最高位符号位，8 位指数，23 位做基数0.0double8 字节，64 位，最高位符号位，11 位做指数，52 位做基数0.0char2 字节，单一的 16 位 Unicode 字符，最小值是 ‘\\u0000’（即为0），最大值是 ‘\\uffff’（即为65,535），可以当整数来用，它的每一个字符都对应一个数字‘\\u0000’booleanfalse数据类型是程序设计语言描述事物、对象的方法。Java数据类型分为内置类型和扩展类型两大类。内置类型就是 Java 语言本身提供的基本数据类型，比如，整型数，浮点数，字符，布尔值等等。而扩展类型则是Java语言根据基本类型扩展出的其他类型，Java要求所有的扩展类型都必须包括在类定义里面，这就是Java为什么是面向对象编程语言的原因。 Java/数据类型2. 包装类：数值型包装类继承于 Number 类，而 Boolean、Character 自己对基本类型数据进行了封装。Byte，public final class Byte extends Number implements ComparableShort，public final class Short extends Number implements ComparableIntegerLongFloatdoubleCharacterBoolean3. 为什么需要包装类？Java 是一种面向对象语言，很多地方都需要使用对象而不是基本数据类型。比如，在集合类中，我们是无法将 int 、double 等类型放进去的。因为集合的容器要求元素是 Object 类型。为了让基本类型也具有对象的特征，就出现了包装类型，它相当于将基本类型“包装起来”，使得它具有了对象的性质，并且为其添加了属性和方法，丰富了基本类型的操作。一些操作1. 基本数据类型与包装类型的转换12345int i = 1;Integer a = Integer.valueOf(i);Integer b = new Integer(1);int j = b.intValue();基本数据类型 -&gt; 包装类型： valueOf 方法；包装类型 -&gt; 基本数据类型： xxxValue 方法2. 自动拆装箱机制Java 1.5 引入自动装箱和拆箱机制，即将基本数据类型与对应的包装类型进行自动转换，自动拆装箱的实现就是应用的 valueOf 方法与 xxxValue 方法。12345List&lt;Integer&gt; integerList = new ArrayList&lt;Integer&gt;();integerList.add(1); // 自动装箱，集合声明的元素为 Integer 类型，但可以直接添加 int 类型数据Integer a = new Integer(1);int b = a; // 自动拆箱，一个 Integer 对象也可直接赋值给 int 类型数据一些问题1. boolean 类型数据大小Oracle Java 文档指出，boolean 类型数据表示一个 bit 位的信息，但是其大小并不是确定的（The boolean data type has only two possible values: true and false. Use this data type for simple flags that track true/false conditions. This data type represents one bit of information, but its “size” isn’t something that’s precisely defined.）后来有人做了实验，定义很多个 boolean 类型数据和 int 类型数据，输出它们占用的空间，发现 int 类型数据占用内存大概是 boolean 类型数据的 4 倍，得到 boolean 类型数据大小为 1 字节的结论。Stack Overflow 上面也有相关讨论，指出单个 boolean 类型数据占用 1 bit，而 boolean 数组每个元素占用 1 字节。总而言之，boolean 数据类型大小定义，占用 1 bit 或 1 字节并不能一概而论，要看具体场景。The Java™ TutorialsJava中boolean到底占几个字节Stack Overflow 参考3. 基本数据类型缓存机制12345Integer f1 = 100, f2 = 100, f3 = 150, f4 = 150;System.out.println(f1 == f2); // trueSystem.out.println(f3 == f4); // falseSystem.out.println(f1.equals(f2)); // trueSystem.out.println(f3.equals(f4)); // true在自动装箱的时候，JVM 会缓存 -128 ~ 127 之间的 int 值，所以当该 int i &gt;= -128 &amp;&amp; i &lt;= 127 时，会直接返回已缓存的 Integer 对象，否则新建一个 Integer 对象。12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125;f1 == f2 返回 true ，是因为 Integer f1 = 100 发生了自动装箱操作。f3 == f4 返回 false，是因为 150 不在那个缓存区间，所以返回的是新的对象，所以不相等。4. 三目运算符引发的空指针异常1234Map&lt;String,Boolean&gt; map = new HashMap&lt;String, Boolean&gt;();Boolean b = (map!=null ? map.get(\"test\") : false); // 抛出 NullPointerExceptionBoolean b = (map!=null ? map.get(\"test\") : Boolean.FALSE); // 正确做法，都转换为对象，就不会发生拆箱操作三目运算符，当第二个参数和第三个参数是基本类型和对象时，会对对象进行拆箱操作，那么 map.get(“test”) 转换为 map.get(“test”).booleanValue()，由于 map.get(“test”) 为 null，而 null.booleanValue() 就会抛出空指针异常。正确的做法就是将三目运算符第二个参数和第三个参数的类型一致即可。自动拆箱导致空指针异常5. void 是否是基本数据类型？Void 类是一个不可实例化的占位符类，它持有对 Java 关键字 void 的 Class 对象的引用。值类型或者引用类型的数据不同，表现在内存的分配方式，由于 void 不能 new 出对象，也就不能在堆中分配值，那就是一开始在栈中分配好空间了，所以这样也可以说它是基本数据类型。不过绝大部分场合说 8 种是没有问题的。Java中Void是基本类型吗？基本类型是8种还是9种？JDK 中文在线博客参考一文读懂什么是Java中的自动拆装箱Java的自动拆装箱","categories":[],"tags":[{"name":"Java Core","slug":"Java-Core","permalink":"http://suiyia.github.io/tags/Java-Core/"}]},{"title":"canal学习一：本地运行 canal","slug":"canal学习一：本地运行-canal","date":"2019-10-13T07:14:00.000Z","updated":"2019-10-13T07:15:06.365Z","comments":true,"path":"2019/10/13/canal学习一：本地运行-canal/","link":"","permalink":"http://suiyia.github.io/2019/10/13/canal学习一：本地运行-canal/","excerpt":"","text":"1. 介绍a. canal 是什么？MySQL 数据库 Binlog 的增量订阅 &amp; 消费组件。简单来说，它可以监测 MySQL 的数据变化情况。b. 用途数据同步、主从复制、数据库镜像等业务场景。主要内容： 本地运行 canal，对数据库进行数据变更，查看 canal 输出结果。运行环境： Ubuntu 18.04 LTS ；虚拟机，内存分配 4G；Windwos 系统运行步骤类似。2. 基本环境配置git：apt install gitmaven：apt install mavenMySQL：安装地址，目前 canal 开源版本支持支持 5.7 及以下的版本如果已经安装 MySQL，先查看 MySQL 版本，版本太高或太低会有兼容性问题。1mysql&gt; select version();更改 MySQL 配置，目录为 /etc/mysql/mysql.conf.d/mysqld.cnf，Windows 系统配置文件在 C:\\ProgramData\\MySQL\\MySQL Server 5.7，文件的开头已经标明「The MySQL database server configuration file」，在 [mysqld] 下面增加如下字段：12345678[mysqld]log-bin=mysql-bin #添加这一行就okbinlog-format=ROW #选择row模式server_id=1 #配置mysql replaction需要定义，不能和canal的slaveId重复重启 MySQL，执行：mysql &gt; SHOW MASTER STATUS; // 看是否有结果，返回 binlog 名称以及位置mysql &gt; SHOW VARIABLES LIKE '%binlog_format%'; // 查看配置文件是否生效，应该返回 ROW创建子用户，赋予相关权限，用于读取 MySQL Binlog 日志1234CREATE USER canal IDENTIFIED BY 'canal'; GRANT SELECT, SHOW VIEW, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';-- GRANT ALL PRIVILEGES ON *.* TO 'canal'@'%' ; 需要具有SHOW VIEW 权限FLUSH PRIVILEGES;JDK：安装配置地址，并设置 JAVA_HOME 路径3. canal 本地运行a. 下载解压，并修改配置文件release 下载页 ，下载解压 canal.deployer-xxx.tar.gz编辑 canal.deployer-xxx/conf/example/instance.properties，下面是需要注意12345canal.instance.master.address = 127.0.0.1:3306 # Mysql 地址端口canal.instance.dbUsername = canal # 用于读取 binlog 日志的用户，测试环境可以用 root 用户代替canal.instance.dbPassword = canalcanal.instance.defaultDatabaseName = test # 选择对 test 数据库进行监控canal.instance.filter.regex = .\\.. # 正则匹配需要监控的表b. 运行canal.deployer-xxx/bin 目录下，运行 ./startup.sh查看日志：vi logs/example/example.log，vi logs/canal/canal.log 查看 canal 是否报错。c. 对数据库 test 进行数据变更，查看 canal 输出demo 工程下载地址，下载 canal.example-xxx.tar.gz ，bin 目录下直接执行 ./startup.sh进入 canal.example-xxx/logs 目录，对数据库进行增删改操作，可以发现有输出，那么 canal 的本地运行算是成功了。4. 配置文件解读下载 release 包 ，其中配置可以分为两个部分：canal.properties：系统根配置文件，分为两个小部分。common argument 定义全局 canal server 属性，destinations 定义多个 instance 的部分属性instance.properties：具体的单个实例的配置1. canal.properties 配置如下，主要讲解我觉得需要注意的地方：123456789101112131415161718192021222324########################################################## common argument ############# 定义 canal server 属性#################################################canal.id= 1canal.ip= # canal server 绑定的本地IP信息，如果不配置，默认选择一个本机IP进行启动服务canal.port=11111 #canal server 对外提供服务的端口canal.zkServers=127.0.0.1:2181 # canal server 链接 zookeeper 集群的链接信息，多个用 逗号分隔# tcp, kafka, RocketMQ canal.serverMode = tcp # 服务方式，默认为 tcp，如果需要将 canal 消息发送到 kafka 就选 kafkacanal.instance.tsdb.dbUsername=canal # 数据库用户名canal.instance.tsdb.dbPassword=canal # 密码########################################################## destinations ############# instance列表定义，列出当前server上有多少个instance#################################################canal.destinations= example # 当前server上部署的instance列表，定义了canal.destinations后，需要在canal.conf.dir对应的目录下建立同名的文件，多个实例用 逗号分隔 canal.destinations = example1,example2# conf root dircanal.conf.dir = ../conf # auto scan instance dir add/remove and start/stop instancecanal.auto.scan = true # instance 文件变化会立马表现出，不用重新启动 canal servercanal.auto.scan.interval = 5canal.instance.global.mode = spring canal.instance.global.lazy = falsecanal.instance.global.spring.xml = classpath:spring/file-instance.xml # canal 实例通过 file-instance.xml 方式加载2. instance.properties 单个实例的具体配置，每个 canal.destinations 内定义的实例都会有这个配置文件1234567canal.instance.master.address=127.0.0.1:3306 # 监控的数据库地址canal.instance.dbUsername=canal # 监控的数据库用户名canal.instance.dbPassword=canalcanal.instance.connectionCharset = UTF-8canal.instance.defaultDatabaseName =test # 选择监控的数据库canal.instance.filter.regex=.*\\\\..* # 白名单，选择监控哪些表canal.instance.filter.black.regex= # 黑名单，选择不监控哪些表5. 本地运行遇到的问题Windows 平台运行 canal，点击 startup.bat 秒退。解决：在 startup.bat 最后添加 pause，查看具体报错原因‘Error: missing ‘server’ JVM at `C:\\Program Files (x86)\\Java\\jre1.8.0_181\\bin\\server\\jvm.dll’解决：环境配置问题，将 Java\\jre1.8.0_181\\bin\\client 文件夹内文件移动到 Java\\jre1.8.0_181\\bin\\server 目录下，没有 server 目录就新建一个。参考异常 [MultiStageCoprocessor-other-example-0] WARN com.taobao.tddl.dbsync.binlog.LogDecoder - Decoding Query failed from: binlog.000012:2831 java.io.IOException: Read Q_FLAGS2_CODE error: limit excceed: 64解决： 兼容性问题，使用 MySQL 5.7 ，该错误会在后续版本更新 https://github.com/alibaba/canal/wiki/BinlogChange%28MySQL8%29","categories":[],"tags":[{"name":"canal","slug":"canal","permalink":"http://suiyia.github.io/tags/canal/"}]},{"title":"MQTT 简单介绍与实现","slug":"MQTT-简单介绍与实现","date":"2019-10-13T07:10:00.000Z","updated":"2019-10-13T07:13:03.966Z","comments":true,"path":"2019/10/13/MQTT-简单介绍与实现/","link":"","permalink":"http://suiyia.github.io/2019/10/13/MQTT-简单介绍与实现/","excerpt":"","text":"1. MQTT 介绍它是一种 机器之间通讯 machine-to-machine (M2M)、物联网 Internet of Things （IoT）常用的一种轻量级消息传输协议适用于网络带宽较低的场合包含发布、订阅模式，通过一个代理服务器（broker），任何一个客户端（client）都可以订阅或者发布某个主题的消息，然后订阅了该主题的客户端则会收到该消息1.1 消息主题发布消息或者订阅消息都要选定一个消息主题，消息主题可以任意定制，类似文件系统，用 “/” 进行分隔，例如主题为 /a/b/c/d 的消息客户端可以使用完全字符匹配消息，也可以使用通配符进行消息匹配通配符 + ：替换任意单个层级。比如订阅 /a/b/c/d、/a/+/c/d 、+/+/+/+ 主题的消息即可收到主题为 /a/b/c/d 的消息，而 b/+/c/d 、 +/+/+ 不会匹配通配符 # ：匹配任意层级，只能用于末尾， #、a/# 可以匹配上面的主题消息长度为 0 的主题层级也是允许的。比如发布主题为 a//topic 的消息，客户端可以用 a/+/topic 进行匹配。/a/topic 的主题用 +/a/topic、#、/# 可以匹配。1.2 服务质量（Quality of Service，QoS）MQTT 定义了三种客户端与代理服务器之间消息到达的难度0：broker/client 之间消息传一次，并不确认传到没有，消息可能丢失1：broker/client 之间消息至少一次，带确认消息的传输，可能重复收到2：broker/client 之间消息仅有一次，利用四次握手进行确认，网络延迟可能会增加当客户端订阅的消息质量与代理服务器发布主题的质量不同时，客户端会选择难度最小的 QoS 接收消息发布等级为 2 ，客户端订阅等级为 0， 那么客户端接收到的 QoS = 0发布等级为 0 ，订阅等级为 2，那么客户端接收到的 QoS = 01.3 消息保留即当 broker 正在发送消息给 client 时，消息会保存，如果此时有新的 client 订阅了该主题的消息，那么它也会收到消息。这种做法的好处就是当消息主题经常变换的时候，如果有新的 client 订阅该消息，那么它不用等待太长的时间就可以收到消息1.4 会话清除client 可以设置 clean session 标志位，当 clean session = false 时，client 失去连接时， broker 会一直保留消息直到 client 重新连接。而 clean session = true 时，broker 会清除所有的消息当这个 client 失去连接。1.5 消息意愿当 client 连接上 broker 时，client 会提示 broker 它有一个意愿消息，这个意愿消息将会在 client 失去连接时，broker 发送出去。消息意愿和普通消息一样都包含主题和内容。2. 实例用实例验证上面的概念2.1 代理服务器实现了 MQTT 的代理服务器有很多种，我们使用 mosquitto2.2 mosquitto 实现过程下载安装 mosquitto，进入 mosquitto 安装目录，新开当前目录的命令行 A，执行命令 mosquitto -c mosquitto.conf，表示通过执行这个配置文件实现代理服务，如果命令窗口没有任何输出表示启动成功，配置文件内容介绍可以自己网上了解然后在当前目录下，新开命令行 B，执行 mosquitto_sub -t name，表示订阅主题为 name 的消息同样在当前目录，新开命令行 C，执行 mosquitto_pub -t name -m 123，表示发布主题为 name ，内容为 123 的消息命令行 B 收到 123 消息表示整个过程实现 OK2.3 一个 Chorme 应用这里介绍一个能够监听本地 MQTT 消息的应用 MQTTLens，去 Chorme 网上应用店下载安装好后新建连接，配置如下圆角图标是绿色表示连接成功接下来你就可以在软件里面，订阅、发布任意 MQTT 消息了，非常方便！博文参考MQTT再学习 – 搭建MQTT服务器及测试","categories":[],"tags":[{"name":"MQTT","slug":"MQTT","permalink":"http://suiyia.github.io/tags/MQTT/"}]},{"title":"SpringJDBC 用法总结","slug":"SpringJDBC-用法总结","date":"2019-10-13T07:09:00.000Z","updated":"2019-10-13T07:09:50.969Z","comments":true,"path":"2019/10/13/SpringJDBC-用法总结/","link":"","permalink":"http://suiyia.github.io/2019/10/13/SpringJDBC-用法总结/","excerpt":"","text":"大部分网上的 Spring 教程大多讲解的是 SSM 框架，其中的 M 现在指的是 MyBatis 这个第三方 ORM 框架，在我看来，MyBatis 有它的优越性，如 SQL 语句与业务代码分离，业务逻辑处理很灵活等。但是在小型业务系统开发时，由于 SSM 框架定义过于规范，开发具体功能时，会写很多接口，而真正的业务逻辑得不到较优的处理，呆板的框架应用反而适得其反。本文主要介绍 SpringJDBC 的基础操作，方便研发人员快速的实现数据的增删改查，而不仅仅拘泥于繁重的、各种框架组合而成的项目之中。SpringJDBC 封装了基础的 JDBC 操作，让我们不用去关心 获取驱动、建立连接、关闭连接等非业务操作，让我们更加专注于业务的实现。本文将对 SpringJDBC 的用法进行介绍，文主要内容如下：基本的数据操作自增主键的获取1. 基本的数据操作1.1 更改更改 主要使用的是 update 方法重载方法：主要包括三种，按需选择，下面展示的从简单到复杂。1234sql = \"insert into customer(name,age)values (?,?)\";int rows = jdbcTemplate.update(sql,\"周杰伦\",35);int rows1 = jdbcTemplate.update(sql,new Object[]&#123;\"周杰伦\",35&#125;);int rows2 = jdbcTemplate.update(sql,new Object[]&#123;\"周杰伦\",35&#125;,new int[]&#123;Types.VARCHAR,Types.DECIMAL&#125;); // 显式指定数据类型批量更改：一次性执行多条 update 语句，使用 batchUpdate 方法jdbcTemplate.batchUpdate(String[] sql); 固定参数值jdbcTemplate.batchUpdate(sql, new BatchPreparedStatementSetter()); 可变参数值123456789101112131415161718192021String sql1 = &quot;insert into customer(NAME,AGE) values (1,1)&quot;;String sql2 = &quot;insert into customer(NAME,AGE) values (1,1)&quot;;String sql3 = &quot;insert into customer(NAME,AGE) values (1,1)&quot;;String[] strings = new String[]&#123;sql1,sql2,sql3&#125;;int[] a = jdbcTemplate.batchUpdate(strings); // 固定参数的多条 SQL 语句组成一个数组传入System.out.println(Arrays.toString(a));sql = &quot;insert into customer(NAME,AGE) values (?,?)&quot;;final List&lt;String&gt; list = new ArrayList&lt;String&gt;()&#123;&#125;;list.add(&quot;1&quot;);list.add(&quot;2&quot;);list.add(&quot;3&quot;);int[] b = jdbcTemplate.batchUpdate(sql, new BatchPreparedStatementSetter() &#123; // 带可变参数的 SQL 语句传入 public void setValues(PreparedStatement preparedStatement, int i) throws SQLException &#123; preparedStatement.setString(1,list.get(i)); preparedStatement.setString(2,list.get(i)); &#125; public int getBatchSize() &#123; return list.size(); &#125;&#125;);System.out.println(Arrays.toString(b));1.2 查询查询 主要使用的是 query、queryForXX 等函数，而 queryForXX 系列底层其实调用的是 query 方法，故这里只介绍通过 query 方法查询数据。query 有多个重载方法，例如传入固定参数的 SQL 语句，传入可变参数的 SQL 语句等等，语法类似上面介绍的 update 方法，这里介绍两种带回调方法的查询语句：(1) void query(String sql, RowCallbackHandler rch)使用 RowCallbackHandler 既可以返回单行结果，也可以返回多行结果。Spring 会对查询的结果集逐行调用 processRow 方法，用户不用关心怎么读取下一行数据的问题。12345678910111213141516171819202122232425sql = \"select CUST_ID,NAME,AGE from customer where CUST_ID = ?\";final Customer customer = new Customer();// 查询单行数据jdbcTemplate.query(sql, new Object[]&#123;1&#125;, new RowCallbackHandler() &#123; public void processRow(ResultSet resultSet) throws SQLException &#123; customer.setCUST_ID(Integer.parseInt(resultSet.getString(\"CUST_ID\"))); customer.setNAME(resultSet.getString(\"NAME\")); customer.setAGE(Integer.parseInt(resultSet.getString(\"AGE\"))); &#125;&#125;);System.out.println(customer.toString()); // Customer&#123;CUST_ID=1, NAME='张三', AGE=12&#125;sql = \"select CUST_ID,NAME,AGE from customer\";final List&lt;Customer&gt; customerList = new ArrayList&lt;Customer&gt;();final Customer customer1 = new Customer();// 查询到多行数据，代码与上面没有区别，唯一的不同就是将结果集存入 ListjdbcTemplate.query(sql, new RowCallbackHandler() &#123; public void processRow(ResultSet resultSet) throws SQLException &#123; customer1.setCUST_ID(Integer.parseInt(resultSet.getString(\"CUST_ID\"))); customer1.setNAME(resultSet.getString(\"NAME\")); customer1.setAGE(Integer.parseInt(resultSet.getString(\"AGE\"))); customerList.add(customer1); &#125;&#125;);System.out.println(customerList);// [Customer&#123;CUST_ID=38, NAME='3', AGE=3&#125;, Customer&#123;CUST_ID=38, NAME='3', AGE=3&#125;](2)T queryForObject(String sql, RowMapperrowMapper)使用 RowMapper 处理结果集，它直接返回的是 List，相比于上面，我们不用手动将对象添加到 List 中123456789101112sql = \"select CUST_ID,NAME,AGE from customer\";List&lt;Customer&gt; customerList = jdbcTemplate.query(sql, new RowMapper&lt;Customer&gt;() &#123; public Customer mapRow(ResultSet resultSet, int i) throws SQLException &#123; Customer customer = new Customer(); customer.setCUST_ID(Integer.parseInt(resultSet.getString(\"CUST_ID\"))); customer.setNAME(resultSet.getString(\"NAME\")); customer.setAGE(Integer.parseInt(resultSet.getString(\"AGE\"))); return customer; &#125;&#125;);System.out.println(customerList); // [Customer&#123;CUST_ID=38, NAME='3', AGE=3&#125;, Customer&#123;CUST_ID=38, NAME='3', AGE=3&#125;](3) 方法 a 与方法 b 的使用场景与注意事项RowCallbackHandler 接口的实现类是可以有状态，即在多线程环境下，可能会有线程安全的问题。下面代码就展示了其实现类 RowCountCallbackHandler 打印结果集行数的示例，在多线程环境中，若行数发生变化，下面的结果可能不会一致。而 RowMapper 实现类没有这种情况。123RowCountCallbackHandler countCallbackHandler = new RowCountCallbackHandler();jdbcTemplate.query(\"select * from customer\",countCallbackHandler);System.out.println(countCallbackHandler.getRowCount());当处理大结果集时， RowMapper 是将结果集所有数据放到 List中，这会占用大量 JVM 内存。RowCallbackHandler 接口内的 processRow() 方法则是一边获取数据一边处理。RowMapper 是先获取再处理，RowCallbackHandler 边获取边处理。2. 自增主键的获取在数据库层面，一个表往往会有一个主键来唯一标识这一行数据。新增记录时，返回新增记录对应的自增主键值，即返回的该列属性包含两个，一个是自增，另一个是主键。SpringJDBC 提供了对自增主键获取的方法，插入数据时，返回插入数据的主键。定义 KeyHolder 对象即可完成上述功能，步骤如下：执行 statement 语句时，指定绑定主键12345678910111213connection.prepareStatement(sql1,PreparedStatement.RETURN_GENERATED_KEYS) final String sql1 = &quot;insert into customer(name,age)values(?,?)&quot;;KeyHolder keyHolder = new GeneratedKeyHolder();jdbcTemplate.update(new PreparedStatementCreator() &#123; public PreparedStatement createPreparedStatement(Connection connection) throws SQLException &#123; PreparedStatement preparedStatement = connection.prepareStatement(sql1,PreparedStatement.RETURN_GENERATED_KEYS); preparedStatement.setString(1,&quot;suiyia&quot;); preparedStatement.setString(2,&quot;30&quot;); return preparedStatement; &#125;&#125;,keyHolder);System.out.println(keyHolder.getKey().toString());keyHolder 的返回形式Number getKey() 主键是数值类型，单列、一行Map&lt;String,Object&gt; getKeys复合类型，多列、一行List&lt;Map&lt;String,Object&gt;&gt; getKeyList 复合类型、多列、多行3. 小结本文只是对 SpringJDBC 的基本常用操作做了简单介绍，之所以介绍 SpringJDBC，是因为在快速开发的后台系统中，没有足够的时间去写接口等，这种方式在小型简单的系统开发时效率更高。但在大型复杂的系统研发中，踏实写接口，遵守框架的开发规范是很有必要的。","categories":[],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://suiyia.github.io/tags/Spring/"}]},{"title":"canal 与 Kafka 本地运行记录","slug":"canal-与-Kafka-本地运行记录","date":"2019-10-13T07:06:00.000Z","updated":"2019-10-13T07:08:31.564Z","comments":true,"path":"2019/10/13/canal-与-Kafka-本地运行记录/","link":"","permalink":"http://suiyia.github.io/2019/10/13/canal-与-Kafka-本地运行记录/","excerpt":"","text":"本文主要记录 canal 与 kafka 本地运行的过程环境安装canalkafkazookeeper文件配置kafka 配置/config/server.properties123listeners=PLAINTEXT://:9092advertised.listeners=PLAINTEXT://192.168.1.119:9092 # 本机 ip + 端口zookeeper.connect=192.168.1.119:2181 # 本机 ip + 端口canal.properties 配置12canal.serverMode = kafkacanal.destinations= example # 主题mq.yml 配置123456789101112131415161718192021servers: 192.168.1.119:9092 #for rocketmq: means the nameserverretries: 0batchSize: 16384lingerMs: 1bufferMemory: 33554432# Canal的batch size, 默认50K, 由于kafka最大消息体限制请勿超过1M(900K以下)canalBatchSize: 50# Canal get数据的超时时间, 单位: 毫秒, 0为不限超时canalGetTimeout: 100flatMessage: truecanalDestinations: - canalDestination: example topic: example partition: # 不填分区，否则会报错，Invalid partition given with record# #对应topic分区数量# partitionsNum: 3# partitionHash:# #库名.表名: 唯一主键# mytest.person: idinstance.properties12345canal.instance.master.address=127.0.0.1:3306 # 数据库地址端口canal.instance.dbUsername=canalcanal.instance.dbPassword=canalcanal.instance.connectionCharset = UTF-8canal.instance.defaultDatabaseName =test启动启动 Zookeeper1234zkServer.cmd or ./zkServer.sh startout：2018-11-17 13:11:07,366 [myid:] - INFO [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181启动 canal，查看 canal.log 和 example.log 没报错即可1234startup.batout:2018-11-17 13:13:30.933 [destination = example , address = /127.0.0.1:3306 , EventParser] WARN c.a.o.c.p.inbound.mysql.rds.RdsBinlogEventParserProxy - prepare to find start position just last position启动 kafka1kafka-server-start.bat ../../config/server.properties新增 kafka 消费者，订阅主题为 example1kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic example变更数据库数据，查看输出。1&#123;&quot;data&quot;:[&#123;&quot;id&quot;:&quot;123&quot;&#125;],&quot;database&quot;:&quot;test&quot;,&quot;es&quot;:1542431895000,&quot;id&quot;:3,&quot;isDdl&quot;:false,&quot;mysqlType&quot;:&#123;&quot;id&quot;:&quot;int(11)&quot;&#125;,&quot;old&quot;:null,&quot;sql&quot;:&quot;&quot;,&quot;sqlType&quot;:&#123;&quot;id&quot;:4&#125;,&quot;table&quot;:&quot;q&quot;,&quot;ts&quot;:1542431896029,&quot;type&quot;:&quot;INSERT&quot;&#125;异常123456canal 控制台输出：ERROR com.alibaba.otter.canal.server.CanalMQStarter - ack error , clientId:1001 batchId:3209 is not exist , please checkcanal.log 输出：2018-11-17 12:39:59.317 [pool-4-thread-1] ERROR com.alibaba.otter.canal.server.CanalMQStarter - ack error , clientId:1001 batchId:2882 is not exist , please checkcom.alibaba.otter.canal.server.exception.CanalServerException: ack error , clientId:1001 batchId:2882 is not exist , please check2018-11-17 12:39:59.417 [pool-4-thread-1] ERROR com.alibaba.otter.canal.kafka.CanalKafkaProducer - Invalid partition given with record: 1 is not in the range [0...1).org.apache.kafka.common.KafkaException: Invalid partition given with record: 1 is not in the range [0...1).解决：mq.yml partition 不填","categories":[],"tags":[{"name":"canal","slug":"canal","permalink":"http://suiyia.github.io/tags/canal/"},{"name":"kafka","slug":"kafka","permalink":"http://suiyia.github.io/tags/kafka/"}]},{"title":"Docker基本概念","slug":"Docker基本概念","date":"2019-10-13T06:58:00.000Z","updated":"2019-10-13T07:02:41.301Z","comments":true,"path":"2019/10/13/Docker基本概念/","link":"","permalink":"http://suiyia.github.io/2019/10/13/Docker基本概念/","excerpt":"","text":"基本概念镜像（Image）：Docker 镜像是特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建之后也不会被改变。分层存储：镜像由一组文件系统组成，或者说由多层文件系统联合组成，镜像构建会一层层构建，前一层是后一层的基础。容器（Container）：容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。容器存储层：为容器读写而准备的存储层，生命周期与容器一样。数据卷：数据卷直接对宿主主机进行读写，生存周期独立于容器，容器消亡，数据卷不会消亡。仓库（Repository）：存放镜像的地方，供其它服务器使用，类似 Maven 仓库虚悬镜像：拉取镜像时候，新镜像和旧镜像同名，原来镜像的仓库门、标签名就变为 none中间层镜像：镜像构建是一层层的，相同的镜像之会构建一次，然后复用。慎重删除，因为其他镜像可能依赖于它。docker 命令docker pull 拉取镜像docker run -it ubuntu:18.04 bash 运行镜像并拉起 Bash 命令行exit 退出容器docker image ls 列出已下载的顶层镜像，Size 表示各层所占空间总和Docker Hub 大小是压缩过的，本地是解压后占用的，所以大小不一致分层构建，多个镜像如果使用相同的层，那么只会占用一份存储空间docker system df 查看镜像、容器、数据卷占用空间docker image prune 删除虚悬镜像docker image ls -a 列出所有镜像，包括中间层镜像docker image ls ubuntu 根据仓库名列出镜像docker image ls ubuntu:18:04docker image ls -f since=mongo:3.2 列出 mongto:3.2 之后的镜像， -f 是 filter 缩写， since 也可以换成 before1docker image ls --format &quot;table &#123;&#123;.ID&#125;&#125;\\t&#123;&#123;.Repository&#125;&#125;\\t&#123;&#123;.Tag&#125;&#125;&quot; 模板方法，只列出部分，标题也自定义镜像删除docker image rm 删除镜像，可以根据 imageID、镜像名、摘要（sha字段）docker image rm 501 根据 ImageID 前 3 位就可以区分删除docker image rm centos，根据镜像名docker image rm $(docker image ls -q redis) 删除仓库名为 redis 的镜像删除分为两步：Untagged 和 Deleted，一个镜像可能多个标签，所以先 untag 某个标签的镜像；如果一个镜像没有任何依赖，那么就触发 deleted。Dockerfile 制作镜像123FROM nginxRUN echo &apos;&lt;h1&gt;Hello, Docker!&lt;/h1&gt;&apos; &gt; /usr/share/nginx/html/index.htmlRUN apt-get updateFROM 指定基础镜像FROM scratch：这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。接下来所写的指令将作为镜像第一层开始存在。RUN 执行命令，Dockerfile 中每一个指令都会建立一层，然后 commit。要注意镜像是一层层构建的，所以要注意构建的方式。docker build - nginx:v3 . ：构建镜像，最后的 “.” 表示当前目录（上下文路径）镜像构建上下文：镜像构建是在 Docker 引擎完成，本地文件会打包上传过去。docker build - &lt; Dockerfile ：从 Dockerfile 构建镜像COPY：复制文件CMD：启动容器，指定所运行的程序及参数，CMD [ “sh”, “-c”, “echo $HOME” ]ENTRYPOINT：入口点，ENV：设置环境变量，ENV NODE_VERSION 7.2.0，$NODE_VERSION 使用EXPOSE：声明容器打算使用什么端口，而 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 是映射宿主端口和容器端口WORKDIR：指定工作目录，以后各层的构建以此为基础容器docker run -t -i ubuntu:18.04 /bin/bash 启动一个容器并打开终端docker container start 启动一个已终止的容器docker container logs 获取容器输出信息docker container stop 终止容器docker exec -it 69d1 bash 进入容器，退出不会终止容器博客参考Docker — 从入门到实践","categories":[{"name":"Docker","slug":"Docker","permalink":"http://suiyia.github.io/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://suiyia.github.io/tags/Docker/"}]},{"title":"NGINX 配置端口转发","slug":"NGINX-配置端口转发","date":"2019-10-13T06:15:00.000Z","updated":"2019-10-13T06:19:37.700Z","comments":true,"path":"2019/10/13/NGINX-配置端口转发/","link":"","permalink":"http://suiyia.github.io/2019/10/13/NGINX-配置端口转发/","excerpt":"","text":"多个 Springboot 项目运行在不同端口，通过不同路径转发到不同端口http://127.0.0.1:8081/index 访问 webAhttp://127.0.0.1:8082/index 访问 webBhttp://127.0.0.1:8083/index 访问 webC修改后：http://127.0.0.1/a/index 访问 webAhttp://127.0.0.1/b/index 访问 webBhttp://127.0.0.1/c/index 访问 webC1234567891011121314151617181920212223242526272829303132http &#123; ... upstream weba &#123; server 127.0.0.1:8081; &#125; upstream webb &#123; server 127.0.0.1:8082; &#125; upstream webc &#123; server 127.0.0.1:8083; &#125; ... server &#123; ... location /a/ &#123; proxy_pass http://weba/; # proxy_pass http://127.0.0.1:8081/; # 也可以直接写ip+端口 &#125; location /b/ &#123; proxy_pass http://webb/; &#125; location /c/ &#123; proxy_pass http://webc/; &#125; ... &#125;&#125;访问某个路径直接跳转到新页面输入 http://127.0.0.1/blog 就会跳转到百度首页123location ^~ /blog &#123; rewrite ^ https://www.baidu.com; &#125;location 与 proxy_pass 斜杠问题nginx proxy_pass末尾神奇的斜线123456server.port=10240@RequestMapping(&quot;/a&quot;)public String helloA(@RequestParam String name)&#123; return &quot;Hello &quot;+ name +&quot; ! now time is &quot;+new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;).format(System.currentTimeMillis());&#125;服务运行在 10240 端口，使用 http://127.0.0.1:10240/a?name=123 即可输出结果proxy_pass 后面加上斜杠，访问 http://127.0.0.1/test1/a?name=123 其实访问 http://127.0.0.1:10240/a?name=123123location ^~/test1/ &#123; proxy_pass http://127.0.0.1:10240/;&#125;proxy_pass 后面没有斜杠，访问 http://127.0.0.1/test1/a?name=123 它其实访问的是 http://127.0.0.1:10240/test1/a?name=123123location ^~/test1/ &#123; proxy_pass http://127.0.0.1:10240;&#125;遇到的问题unknown log format “main” in C:\\nginx-1.17.3/conf/nginx.conf:28打开nginx.conf，”main”错误是因为丢失了log_format选项，之前把他屏蔽掉了，修改之后问题解决。listen 80 端口不生效include /etc/nginx/sites-enabled/*; 注释掉，这个nginx 配置根目录不生效问题权限问题导致Nginx 403 Forbidden错误的解决方法于是在nginx.conf头部加入一行：user root;参考nginx 同一个域名下部署多个工程","categories":[{"name":"nginx","slug":"nginx","permalink":"http://suiyia.github.io/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://suiyia.github.io/tags/nginx/"}]},{"title":"JVM学习——垃圾回收","slug":"JVM学习——垃圾回收","date":"2019-10-13T04:32:00.000Z","updated":"2019-10-13T05:52:28.717Z","comments":true,"path":"2019/10/13/JVM学习——垃圾回收/","link":"","permalink":"http://suiyia.github.io/2019/10/13/JVM学习——垃圾回收/","excerpt":"","text":"确定垃圾引用计数：给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。存在对象之间相互循环引用的问题。根搜索：如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。要注意的是，不可达对象不等价于可回收对象，不可达对象变为可回收对象至少要经过两次标记过程。两次标记后仍然是可回收对象，则将面临回收。Java 四种引用类型：强引用：把一个对象赋给一个引用变量，这个引用变量就是一个强引用软引用：用 SoftReference 类来实现，对于只有软引用的对象来说，当系统内存足够时它不会被回收，当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中。弱引用：用 WeakReference 类来实现，它比软引用的生存期更短，对于只有弱引用的对象来说，只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，总会回收该对象占用的内存。虚引用：PhantomReference 类来实现，它不能单独使用，必须和引用队列联合使用。虚引用的主要作用是跟踪对象被垃圾回收的状态。垃圾回收算法标记-清除：标记需要回收的对象然后统一回收。效率低、碎片多复制： 类似 eden、survivor 将存活的对象复制到另外一块区。标记-整理：结合标记-清除、复制。标记后不是清理对象，而是将存活对象移向内存的一端。然后清除端边界外的对象。分代收集：主流垃圾回收算法，根据对象存活周期不同分配到不同区域。新生代中，每次收集都会有大量对象死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。分区收集：G1垃圾回收器Serial ：简单而高效，单线程，是 Java 虚拟机运行在 Client 模式下默认的新生代垃圾收集器，新生代采用复制算法，老年代采用标记-整理算法。ParNew：Serial 的多线程版本，多个线程并发进行垃圾回收，其它与 Serial 一样。它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器（真正意义上的并发收集器，后面会介绍到）配合工作。并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个CPU上。Parallel Scavenge：新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃圾收集器，重点关注的是程序达到一个可控制的吞吐量，高吞吐量可以最高效率地利用 CPU 时间，尽快地完成程序的运算任务，主要适用于在后台运算而不需要太多交互的任务。自适应调节策略也是ParallelScavenge 收集器与 ParNew 收集器的一个重要区别。吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)Serial Old：Serial 垃圾收集器年老代版本、标记-整理，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。Parallel Old：使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。CMS（Concurrent mark sweep）一种以获取最短回收停顿时间为目标的收集器，它而非常符合在注重用户体验的应用上使用。运行过程：初始标记：标记一下 GC Roots 能直接关联的对象，暂停其他线程、速度很快并发标记：GC tracing 过程，与用户线程一起工作重新标记：修改并发标记期间，程序运行改变标记的部分，暂停其他线程。并发清除：与用户线程一起工作，清除标记的区域。G1，标记-整理并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU或者CPU核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。空间整合：与 CMS 的“标记–清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。博客参考作者：SnailClimb链接：https://juejin.im/post/5b85ea54e51d4538dd08f601来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"JVM","slug":"JVM","permalink":"http://suiyia.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://suiyia.github.io/tags/JVM/"}]},{"title":"JVM学习——类加载机制","slug":"JVM学习——类加载机制","date":"2019-10-12T14:44:00.000Z","updated":"2019-10-22T15:05:10.497Z","comments":true,"path":"2019/10/12/JVM学习——类加载机制/","link":"","permalink":"http://suiyia.github.io/2019/10/12/JVM学习——类加载机制/","excerpt":"","text":"类加载机制加载：从各个地方加载 class 文件（本地、网络、zip、数据库等）到内存中，在内存中就变为方法区的运行时数据结构，在 Java 堆中生成一个代表这个类的 java.lang.Class 对象，作为对方法区中这些数据的访问入口。验证：是否满足当前虚拟机要求文件格式验证，验证字节流是否符合 Class 文件格式的规范，并且能被当前版本的虚拟机处理，该验证的主要目的是保证输入的字节流能正确地解析并存储于方法区之内。经过该阶段的验证后，字节流才会进入内存的方法区中进行存储，后面的三个验证都是基于方法区的存储结构进行的。元数据验证，对类的元数据信息进行语义校验（其实就是对类中的各数据类型进行语法校验），保证不存在不符合 Java 语法规范的元数据信息。字节码验证，该阶段验证的主要工作是进行数据流和控制流分析，对类的方法体进行校验分析，以保证被校验的类的方法在运行时不会做出危害虚拟机安全的行为。符号引用验证，这是最后一个阶段的验证，它发生在虚拟机将符号引用转化为直接引用的时候（解析阶段中发生该转化，后面会有讲解），主要是对类自身以外的信息（常量池中的各种符号引用）进行匹配性的校验。准备：在方法区为类变量分配内存空间，赋初始值（0，null，false等）注意：public static final int v = 8080; 如果类变量加上 final，那么此时值将是赋值的值。final 表示不可变，所以在准备阶段就赋指定值。解析：将常量池中的符号引用替换为直接引用的过程，解析阶段可能开始于初始化之前，也可能在初始化之后开始符号引用，符号引用以一组符号来描述所引用的目标，符号引用可以是任何形式的字面量，符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经在内存中。直接引用，直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是与虚拟机实现的内存布局相关的，同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般都不相同，如果有了直接引用，那引用的目标必定已经在内存中存在。初始化：是执行类构造器方法的过程。方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。123类初始化方法。编译器会按照其出现顺序，收集类变量的赋值语句、静态代码块，最终组成类初始化方法。类初始化方法一般在类初始化的时候执行。对象初始化方法。编译器会按照其出现顺序，收集成员变量的赋值语句、普通代码块，最后收集构造函数的代码，最终组成对象初始化方法。对象初始化方法一般在实例化类对象的时候执行。触发初始化情况遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。当使用 JDK1.7 动态语言支持时，如果一个 java.lang.invoke.MethodHandle实例最后的解析结果 REF_getstatic,REF_putstatic,REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。注意以下几种情况不会执行类初始化：通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。定义对象数组，不会触发该类的初始化。常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触发定义常量所在的类。通过类名获取Class对象，不会触发类的初始化。通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。通过ClassLoader默认的loadClass方法，也不会触发初始化动作接口的初始化过程与类初始化过程的不同。接口也有初始化过程，上面的代码中我们都是用静态语句块来输出初始化信息的，而在接口中不能使用“static{}”语句块，但编译器仍然会为接口生成类构造器，用于初始化接口中定义的成员变量（实际上是 static final 修饰的全局常量）。二者在初始化时最主要的区别是：当一个类在初始化时，要求其父类全部已经初始化过了，但是一个接口在初始化时，并不要求其父接口全部都完成了初始化，只有在真正使用到父接口的时候（如引用接口中定义的常量），才会初始化该父接口。这点也与类初始化的情况很不同，回过头来看第 2 个例子就知道，调用类中的 static final 常量时并不会 触发该类的初始化，但是调用接口中的 static final 常量时便会触发该接口的初始化。使用卸载例子两道面试题，带你解析Java类加载机制确定类变量的初始值。在类加载的准备阶段，JVM 会为类变量初始化零值，这时候类变量会有一个初始的零值。如果是被 final 修饰的类变量，则直接会被初始成用户想要的值。初始化入口方法。当进入类加载的初始化阶段后，JVM 会寻找整个 main 方法入口，从而初始化 main 方法所在的整个类。当需要对一个类进行初始化时，会首先初始化类构造器（），之后初始化对象构造器（）。初始化类构造器。JVM 会按顺序收集类变量的赋值语句、静态代码块，最终组成类构造器由 JVM 执行。初始化对象构造器。JVM 会按照收集成员变量的赋值语句、普通代码块，最后收集构造方法，将它们组成对象构造器，最终由 JVM 执行。类加载器从虚拟机的角度来说，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），该类加载器使用 C++ 语言实现，属于虚拟机自身的一部分。另外一种就是所有其它的类加载器，这些类加载器是由Java语言实现，独立于 JVM 外部，并且全部继承自抽象类 java.lang.ClassLoader。从Java开发人员的角度来看，大部分Java程序一般会使用到以下三种系统提供的类加载器：启动类加载器(Bootstrap ClassLoader) ：负责加载 JAVA_HOME\\lib 目录中的，或通过 -Xbootclasspath 参数指定路径中的，且被虚拟机认可（按文件名识别，如rt.jar）的类。扩展类加载器(Extension ClassLoader)：负责加载 JAVA_HOME\\lib\\ext 目录中的，或通过java.ext.dirs系统变量指定路径中的类库。应用程序类加载器(Application ClassLoader)：负责加载用户路径（classpath）上的类库。 JVM通过双亲委派模型进行类的加载，当然我们也可以通过继承java.lang.ClassLoader实现自定义的类加载器。博客参考两道面试题，带你解析Java类加载机制","categories":[{"name":"JVM","slug":"JVM","permalink":"http://suiyia.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://suiyia.github.io/tags/JVM/"}]},{"title":"JVM学习——运行时数据区","slug":"JVM学习——运行时内存分区","date":"2019-10-11T14:37:00.000Z","updated":"2019-10-22T14:57:10.855Z","comments":true,"path":"2019/10/11/JVM学习——运行时内存分区/","link":"","permalink":"http://suiyia.github.io/2019/10/11/JVM学习——运行时内存分区/","excerpt":"","text":"介绍Java虚拟机在执行 Java 程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域都有各自的用途，已经创建和销毁时间，有的区域随着虚拟机进程的启动而创建，有些区域则依赖用户线程的启动和结束而创建和销毁。Java 文件中定义的方法、变量、常量等进入内存后，存放的区域以及对应的变化。Java 虚拟机内存空间就是一块普通的内存空间，只是这部分处理 Java 程序。Java 虚拟机内存结构按线程数据是否共享分为两部分：线程共享堆方法区常量池线程私有PC 寄存器本地方法栈Java 虚拟机栈各个分区的细节基于 JDK 1.8堆：存放对象的地方Dog dog = new Dog(); new Dog() 这个对象就在堆上堆进一步可分为：年轻代、老年代。年轻代对象大多数存活时间短，很快会被垃圾回收。年轻代存活久的会进入老年代，当然有些对象比较大，会直接进入老年代。年轻代内存分区进一步可分为 Eden、survivor0、survivor1 三个部分，内存默认大小比例为 8:1:1。垃圾回收的时候， Eden 和其中一个 surivor 内的对象大部分会被清除，而没清除的放入另外一个 surivor 中（垃圾回收算法——复制算法）。JDK 1.8 之前，堆中有永久代（Perm GEN）这个概念，JDK 1.8 开始，去掉永久代，取而代之的是元空间（MetaSpace），元空间不属于堆，元空间的大小仅受限于机器的内存大小。当 Perm GEN 属于堆的时候，有时候由于堆内存大小不足，报 “java.lang.OutOfMemoryError: PermGen space” 错误，现在这个错误将不复存在；当然对应的 -XX:MaxPermSize 也将不起作用One important change in Memory Management in Java 8Java 8: From PermGen to MetaspaceJava8内存模型—永久代(PermGen)和元空间(Metaspace)方法区存放类的结构信息：运行时常量池、方法、构造方法方法区是一个接口概念，是 Java 虚拟机定义的一个规范；而永久代、元空间则被认为是方法区这个规范的实现，并且永久代 HotSpot 虚拟机才有的概念，其它虚拟机没有。JDK 1.7 时，永久代包含类的元信息、静态变量、常量池（Constant Pool Table）；JDK 1.8 开始元空间（元空间不属于堆，在机器的本地内存中）存储类的元信息。静态变量、常量池并入堆中。常量池：用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。jdk8之后永久代去哪了？ - Mr Zeng的回答 - 知乎常量池JVM常量池浅析Class 文件常量池 class 文件中有定义，包括字面量和符号引用字面量：比较接近于 Java 层面的常量概念，如文本字符串、被声明为 final 的常量值等符号引用：类和接口的全限定名（即带有包名的 Class 名，如：org.lxh.test.TestClass）字段的名称和描述符（private、static 等描述符）方法的名称和描述符（private、static 等描述符）运行时常量池，JDK1.7 及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。同时在 jdk 1.8中移除整个永久代，取而代之的是一个叫元空间（Metaspace）的区域全局字符串常量池基本类型包装类对象常量池PC（Program Counter） 程序计数器当前线程所执行的字节码的行号指示器。唯一一个无 OOM 的区域如果这个方法不是 native 方法，那么 PC 寄存器就保存 Java 虚拟机正在执行的字节码指令地址。如果是 native 方法，那么 PC 寄存器保存的值是 undefined。任意时刻，一条 Java 虚拟机线程只会执行一个方法的代码，而这个被线程执行的方法称为该线程的当前方法，其地址被存在 PC 寄存器中。本地方法栈「当 Java 虚拟机使用其他语言（例如 C 语言）来实现指令集解释器时，也会使用到本地方法栈。如果 Java 虚拟机不支持 natvie 方法，并且自己也不依赖传统栈的话，可以无需支持本地方法栈。」Java 虚拟机栈一个线程就包含一个虚拟机栈，与线程共存亡。虚拟机栈有大小，如果栈的深度大于 JVM 所允许的范围，会抛出 StackOverflowError；如果申请不到额外空间，会抛出 OutOfMemoryError，这两种错误如果要捕获，需使用 Throwable 进行捕获。描述的是 Java 方法执行的内存模型，线程执行一个方法时，虚拟机栈就会创建一个栈帧，栈帧内包含局部变量表，操作数栈。方法执行完退出，该栈帧就会清除。栈帧内容：局部变量表：是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量，其中存放的数据的类型是编译期可知的各种基本数据类型、对象引用（reference）和 returnAddress 类型（它指向了一条字节码指令的地址）。对象引用：强引用、软引用、弱引用、虚引用。（在垃圾回收里面详细说）操作数栈操作数栈的最大深度也是在编译的时候就确定了，当一个方法开始执行时，它的操作栈是空的，在方法的执行过程中，会有各种字节码指令（比如：加操作、赋值元算等）向操作栈中写入和提取内容，也就是入栈和出栈操作。Java 虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈。基于栈的指令集最主要的优点是可移植性强，主要的缺点是执行速度相对会慢些；而由于寄存器由硬件直接提供，所以基于寄存器指令集最主要的优点是执行速度快，主要的缺点是可移植性差。动态链接每个栈帧都包含一个指向运行时常量池（在方法区中，后面介绍）中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接。Class 文件的常量池中存在有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用为参数。这些符号引用，一部分会在类加载阶段或第一次使用的时候转化为直接引用（如 final、static 域等），称为静态解析，另一部分将在每一次的运行期间转化为直接引用，这部分称为动态连接。方法出口一般来说，方法正常退出时，调用者的 PC 计数器的值就可以作为返回地址，栈帧中很可能保存了这个计数器值，而方法异常退出时，返回地址是要通过异常处理器来确定的，栈帧中一般不会保存这部分信息。博客参考JVM系列第6讲：Java 虚拟机内存结构","categories":[{"name":"JVM","slug":"JVM","permalink":"http://suiyia.github.io/categories/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"http://suiyia.github.io/tags/JVM/"}]},{"title":"MySQL学习——基础概念了解","slug":"MySQL学习——基础概念了解","date":"2019-10-10T13:44:00.000Z","updated":"2019-10-11T14:19:28.444Z","comments":true,"path":"2019/10/10/MySQL学习——基础概念了解/","link":"","permalink":"http://suiyia.github.io/2019/10/10/MySQL学习——基础概念了解/","excerpt":"","text":"MySQL 主从复制原理https://zhuanlan.zhihu.com/p/50597960MySQL主从复制涉及到三个线程主节点 binary log dump 线程当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。从节点 I/O线程当从节点上执行start slave命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中。从节点SQL线程SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。binlog 记录格式基于SQL语句，只需要记录会修改数据的sql语句到binlog中，减少了binlog日质量，节约I/O，提高性能。缺点是在某些情况下，会导致主从节点中数据不一致（比如sleep(),now()等）。基于行，只记录哪条数据被修改了，修改成什么样。优点是不会出现某些特定情况下的存储过程、或者函数、或者trigger的调用或者触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是修改table的时候会让日志暴增,同时增加bin log同步时间。也不能通过bin log解析获取执行过的sql语句，只能看到发生的data变更。混合模式，一般的复制使用STATEMENT模式保存到binlog，对于STATEMENT模式无法复制的操作则使用ROW模式来保存，MySQL会根据执行的SQL语句选择日志保存方式。日志类型错误日志，记录出错信息，也记录一些警告信息或者正确的信息查询日志，记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行慢查询日志，设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。二进制日志，记录对数据库执行更改的所有操作中继日志，事务日志数据类型（https://juejin.im/entry/5b57ec015188251aa8292a69）整数类型，包括TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT，分别表示1字节、2字节、3字节、4字节、8字节整数。实数，包括FLOAT、DOUBLE、DECIMAL。DECIMAL可以用于存储比BIGINT还大的整型，能存储精确的小数。而FLOAT和DOUBLE是有取值范围的，并支持使用标准的浮点进行近似计算。计算时FLOAT和DOUBLE相比DECIMAL效率更高一些，DECIMAL你可以理解成是用字符串进行处理。字符串类型，包括 VARCHAR、CHAR、TEXT、BLOB。VARCHAR 用于存储可变长字符串，它比 CHAR 定长类型更节省空间；当CHAR值被存储时，它们被用空格填充到特定长度，检索CHAR值时需删除尾随空格。枚举类型，把不重复的数据存储为一个预定义的集合。有时可以使用ENUM代替常用的字符串类型。ENUM存储非常紧凑，会把列表值压缩到一个或两个字节。ENUM在内部存储时，其实存的是整数。尽量避免使用数字作为ENUM枚举的常量，因为容易混乱。排序是按照内部存储的整数日期时间类型，尽量使用timestamp，空间效率高于datetime，用整数保存时间戳通常不方便处理。如果需要存储微妙，可以使用bigint存储。CHAR和VARCHAR的区别？CHAR和VARCHAR类型在存储和检索方面有所不同CHAR列长度固定为创建表时声明的长度，长度值范围是1到255当CHAR值被存储时，它们被用空格填充到特定长度，检索CHAR值时需删除尾随空格。MYSQL中varchar(10)和int(10)的区别 TODOSQL 语句分类DDL：数据定义语言（create drop alter）DML：数据操作语句（insert update delete）DQL：数据查询语句（select ）DCL：数据控制语句，进行授权和权限回收（grant revoke）TPL：数据事务语句（commit collback savapoint）数据库范式减少数据冗余、查询需要多表关联第一范式：属性具有原子性，不可再分解。第二范式：记录具有唯一标识，即实体唯一性。通常需要为表加上一个列， 以存储各个实例的惟一标识。第三范式：任何字段不能由其它字段派生而来，要求字段没有冗余。第三范式具有如下特征：1， 每一列只有一个值。2， 每一行都能区分。3， 每一个表都不包含其他表已经包含的非主关键字信息。MyISAM表格将在哪里存储，并且还提供其存储格式?每个MyISAM表格以三种格式存储在磁盘上：“.frm”文件存储表定义数据文件具有“.MYD”(MYData)扩展名索引文件具有“.MYI”(MYIndex)扩展名其它一条SQL语句在MySQL中是如何执行的MySQL 主从复制原理MySQL经典面试题","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://suiyia.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://suiyia.github.io/tags/MySQL/"}]},{"title":"MySQL学习——锁","slug":"MySQL学习——锁","date":"2019-10-10T13:40:00.000Z","updated":"2019-10-11T13:09:53.224Z","comments":true,"path":"2019/10/10/MySQL学习——锁/","link":"","permalink":"http://suiyia.github.io/2019/10/10/MySQL学习——锁/","excerpt":"","text":"锁加锁策略乐观锁：乐观锁总是假设最好的情况，乐观锁常见实现：版本号控制，数据行保存 version 字段，修改时会变化。MySQL-InnoDB-MVCC多版本并发控制CAS 算法（compare and swap），CAS算法涉及到三个操作数，需要读写的内存值 V，进行比较的值 A，拟写入的新值 B。 当且仅当 V 的值等于 A 时，CAS 通过原子方式用新值 B 来更新 V 的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。CAS 常见问题ABA问题：一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值。在这段时间它的值可能被改为其他值，然后又改回A循环时间长开销大：自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。只能保证一个共享变量的原子操作：CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。悲观锁：总是假设最坏的情况，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程锁粒度分类表锁，粒度最大，对当前操作的整张表加锁，实现简单，资源消耗也比较少，加锁快，不会出现死锁 。行锁，粒度最小 的一种锁，只针对当前操作的行的索引进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，会出现死锁。InnoDB支持的行级锁：Record Lock: 对索引项加锁，锁定符合条件的行。Gap Lock: 对索引项之间的“间隙”加锁，不包括记录本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。Next-key Lock： 锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合。可解决幻读问题。页锁，开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。相关知识点：innodb对于行的查询使用next-key lockNext-locking keying为了解决Phantom Problem幻读问题当查询的索引含有唯一属性时，将next-key lock降级为record keyGap锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生有两种方式显式关闭gap锁：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC B. 将参数innodb_locks_unsafe_for_binlog设置为1锁可写分类共享锁（S），如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不 能加排他锁。获取共享锁的事务只能读数据，不能修改数据。排他锁（X），如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的封锁。获取排他锁的事务既能读数据，又能修改数据。意向共享锁（IS）： 表示事务准备给数据行记入共享锁，事务在一个数据行加共享锁前必须先取得该表的IS锁。意向排他锁（IX）： 表示事务准备给数据行加入排他锁，事务在一个数据行加排他锁前必须先取得该表的IX锁。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://suiyia.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://suiyia.github.io/tags/MySQL/"}]},{"title":"MySQL学习——事务","slug":"MySQL学习——事务","date":"2019-10-10T13:39:00.000Z","updated":"2019-10-11T14:18:40.674Z","comments":true,"path":"2019/10/10/MySQL学习——事务/","link":"","permalink":"http://suiyia.github.io/2019/10/10/MySQL学习——事务/","excerpt":"","text":"事务一系列操作，事务中的操作要么全部成功，要么全部失败。事务四大特性（ACID）原子性：事务中所有操作，要么全部成功；要么撤回到执行事务之前的状态。一致性：事务的执行使得数据库从一种正确状态转换成另一种正确状态。隔离性：事务操作之间彼此独立和透明互不影响。持久性：事务一旦提交，其结果就是永久的。即便发生系统故障，也能恢复。并发事务带来的问题脏读（Dirty Read）：一个事务可以读取其他事务未提交的执行结果丢失修改（Lost to modify）：第一个事务中修改了这个数据后，第二个事务也修改了这个数据。不可重复读（Nonrepeatable Read）：在同一次事务中，同一个查询在 T1 时间内读取某一行，在 T2 时间重新读取这一行，这一行发生了 UPDATE 或者 DELETE。幻读（Phantom Read）：用户读取某一范围的数据行时，另外一个事务在范围内 插入 insert 了新行，用户再次读取时，发现新的幻影行。不可重复读重点在于 update 和 delete，而幻读的重点在于 insert。InnoDB 通过多版本并发控制（MVCC，Multiversion Conccurrency Control）解决不可重复读问题，在此基础上通过间隙锁解决幻读问题。事务隔离级别（解决并发事务带来的问题）读未提交（Read Uncommited）：所以事务能够看到其它未提交事务的结果。读已提交（Read Commited）：一个事务只能看到其它已经提交事务的结果。可重复读（Repeatable Read）：MySQl 默认事务级别，确保同一事务的多个实例在并发读取数据时，会看到相同的数据行。幻读（）串行化（Serializable）：强制事务排序，使之不可能出现冲突。在读取的数据行上面加上共享锁事务保证数据一致性原理（TODO）redo log 进入 prepare 状态记录 binlog最后 redo log 改为提交状态。事务日志是通过redo和innodb的存储引擎日志缓冲（Innodb log buffer）来实现的，当开始一个事务的时候，会记录该事务的lsn(log sequence number)号; 当事务执行时，会往InnoDB存储引擎的日志的日志缓存里面插入事务日志；当事务提交时，必须将存储引擎的日志缓冲写入磁盘（通过innodb_flush_log_at_trx_commit来控制），也就是写数据前，需要先写日志。这种方式称为“预写日志方式”事务怎么通过日志实现的redo log 重做日志，用来恢复数据，用于保障已提交事务的持久化特性。内存中的重做日志缓冲重做日志文件undo log 回滚日志，用于记录数据被修改前的信息，用于保障事务的原子性。一文了解InnoDB事务实现原理","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://suiyia.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://suiyia.github.io/tags/MySQL/"}]},{"title":"MySQL学习——索引","slug":"MySQL学习——索引","date":"2019-10-10T13:38:00.000Z","updated":"2019-10-11T14:00:34.161Z","comments":true,"path":"2019/10/10/MySQL学习——索引/","link":"","permalink":"http://suiyia.github.io/2019/10/10/MySQL学习——索引/","excerpt":"","text":"索引索引是一种数据结构,可以帮助我们快速的进行数据的查找。InnoDB 存储引擎的默认索引实现为 B+ 树索引。索引分类普通索引（index）：最基本的索引，没有任何约束限制。唯一索引（unique）：和普通索引类似，但是具有唯一性约束，允许有空值，一个表可以有多个唯一索引。主键索引（primary key）：特殊的唯一索引，不允许有空值，保证实体完整性，一个表只能有一个主键。联合索引：将多个列组合在一起创建索引，可以覆盖多个列。（也叫复合索引，组合索引）全文索引：主要用于查找文本中的关键字，并不是直接与索引中的值进行比较。fulltext 更像是一个搜索引擎，配合 match against 操作使用，而不是一般的 where 语句加 like。索引实现MyISAM 和 InnoDB 都使用 B+Tree 实现。MyISAM 叶子节点存放数据记录的地址，要找到该数据还需要去该地址寻找。InnoDB 叶子节点就是数据本身，数据表的主键作为索引的 key。聚簇索引，MySQL索引是用一种叫做聚簇索引的数据结构实现的，是一种数据存储方式，它实际上是在同一个结构中保存了 B+ 树索引和数据行，InnoDB 表是按照聚簇索引组织的（类似于Oracle的索引组织表）。聚簇索引的叶节点就是数据节点，而非聚簇索引的叶节点仍然是索引节点，并保留一个链接指向对应数据块。explain 用法字段含义(分析是否有用到索引)https://www.sunjs.com/article/detail/99169a7375834c158409036934f10fab.htmlid 表示一个查询中各个子查询的执行顺序，id相同执行顺序由上至下。 id不同，id值越大优先级越高，越先被执行。id为 null 时表示一个结果集，不需要使用它查询，常出现在包含union等查询语句中。select_type 表示查询中每个 select 子句的类型：SIMPLE 不包含任何子查询或union等查询PRIMARY 包含子查询最外层查询就显示为 PRIMARYSUBQUERY 在select或 where字句中包含的查询DERIVED from字句中包含的查询UNION 出现在union后的查询语句中UNION RESULT 从UNION中获取结果集table 查询的数据表，当从衍生表中查数据时会显示 x ，表示对应的执行计划idpartitions 表分区、表创建的时候可以指定通过那个列进行表分区。type 表示MySQL在表中找到所需行的方式，又称「访问类型」ALL 扫描全表数据index 遍历索引range 索引范围查找index_subquery 在子查询中使用 refunique_subquery 在子查询中使用 eq_refref_or_null 对Null进行索引的优化的 reffulltext 使用全文索引ref 使用非唯一索引查找数据eq_ref 在join查询中使用PRIMARY KEYorUNIQUE NOT NULL索引关联。possible_keys 可能使用的索引，但不一定被查询使用key 显示MySQL在查询中实际使用的索引，若没有使用索引，显示为NULL; 查询中若使用了覆盖索引(覆盖索引：索引的数据覆盖了需要查询的所有数据)，则该索引仅出现在key列表中key_len 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度ref 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值rows 返回估算的结果集数目，并不是一个准确的值。filteredExtra 包含不适合在其他列中显示但十分重要的额外信息Using index 使用覆盖索引Using where 使用了用where子句来过滤结果集Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。Using temporary 使用了临时表索引失效情况% 开头的 like 模糊匹配or 前后语句没有同时使用索引数据类型出现隐式转化（字符串列查询没有使用引号）索引列进行运算","categories":[{"name":"MySQL","slug":"MySQL","permalink":"http://suiyia.github.io/categories/MySQL/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://suiyia.github.io/tags/MySQL/"}]},{"title":"剑指offer题解 | 链表中倒数第k个节点","slug":"剑指offer题解-链表中倒数第k个节点","date":"2019-09-25T14:45:00.000Z","updated":"2019-09-25T14:44:08.380Z","comments":true,"path":"2019/09/25/剑指offer题解-链表中倒数第k个节点/","link":"","permalink":"http://suiyia.github.io/2019/09/25/剑指offer题解-链表中倒数第k个节点/","excerpt":"","text":"题目描述输入一个链表，输出该链表中倒数第k个结点。解题想法设定两个标志位，low 和 high，high 先走 k-1 步，剩下的 low 和 high 一起走，high 等于 null 时就返回 low 节点考虑链表长度为空，链表长度小于 k 的情况代码实现123456789101112131415161718192021public ListNode FindKthToTail(ListNode head,int k) &#123; if (head == null)&#123; return null; &#125; ListNode low = head; ListNode high = head; for (int i = 0; i &lt;= k-1; i++) &#123; if (head == null &amp;&amp; i &lt; k)&#123; // 链表长度小于 k return null; &#125; high = head.next; head = head.next; &#125; while (high != null)&#123; low = low.next; high = high.next; &#125; return low;&#125;","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 反转链表","slug":"剑指offer题解-反转链表","date":"2019-09-25T14:44:00.000Z","updated":"2019-09-25T15:36:34.199Z","comments":true,"path":"2019/09/25/剑指offer题解-反转链表/","link":"","permalink":"http://suiyia.github.io/2019/09/25/剑指offer题解-反转链表/","excerpt":"","text":"题目描述输入一个链表，反转链表后，输出新链表的表头。解题想法两个索引位保存链的指向信息，然后同步右移，原地反转代码实现1234567891011121314public ListNode ReverseList(ListNode head) &#123; if (head == null)&#123; return null; &#125; ListNode low = null; ListNode high = null; while (head != null)&#123; high = head.next; head.next = low; low = head; head = high; &#125; return low; &#125;","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 调整数组顺序使奇数位于偶数前面","slug":"剑指offer题解-调整数组顺序使奇数位于偶数前面","date":"2019-09-24T15:40:00.000Z","updated":"2019-09-24T15:42:10.869Z","comments":true,"path":"2019/09/24/剑指offer题解-调整数组顺序使奇数位于偶数前面/","link":"","permalink":"http://suiyia.github.io/2019/09/24/剑指offer题解-调整数组顺序使奇数位于偶数前面/","excerpt":"","text":"题目描述输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于数组的后半部分并保证奇数和奇数，偶数和偶数之间的相对位置不变。解题想法插入排序从左自右找到第一个偶数，然后在该位置右边找到第一个奇数，进行交换。代码实现123456789101112131415161718192021222324252627282930313233public void reOrderArray(int [] array) &#123; if (array.length == 0 || array.length == 1)&#123; return; &#125; int i = 0; int j = 0; while (i &lt; array.length)&#123; // 找到第一个偶数 while ((array[i] &amp; 1) == 1)&#123; i++; &#125; j = i + 1; while (j &lt; array.length)&#123; // 找到第一个奇数 if ((array[j] &amp; 1) == 0)&#123; j++; &#125;else &#123; break; &#125; &#125; // 插入排序 if (j &lt; array.length)&#123; int temp = array[j]; for (int k = j-1; k &gt;= i ; k--) &#123; array[k+1] = array[k]; &#125; array[i++] = temp; &#125;else &#123; break; &#125; &#125;&#125;","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 数值的整数次方","slug":"剑指offer题解-数值的整数次方","date":"2019-09-24T14:22:00.000Z","updated":"2019-09-24T14:58:09.152Z","comments":true,"path":"2019/09/24/剑指offer题解-数值的整数次方/","link":"","permalink":"http://suiyia.github.io/2019/09/24/剑指offer题解-数值的整数次方/","excerpt":"","text":"题目描述给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。保证base和exponent不同时为0解题想法主要考察 指数函数 的特征以及程序的健壮性底数不能为负数底数为 0 时，0 的 n 次方始终为 0指数为 0 时，且任意数的 0 次方都是 1指数为负数时，结果是越来越小的常规思路：循环累乘，时间复杂度 0（N）递归思路：当n为偶数，a^n =（a^n/2）×（a^n/2），当 n为奇数，a^n = a^[(n-1)/2] × a^[(n-1)/2] * a代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 循环思路public double Power(double base, int exponent) &#123; if (base == 0 )&#123; return 0; &#125; if (exponent == 0)&#123; return 1; &#125; boolean flag = false; if (exponent &lt; 0)&#123; exponent = -1*exponent; flag = true; &#125; double result = 1; for (int i = 0; i &lt; exponent; i++) &#123; result = result * base; &#125; if (flag)&#123; return 1.0/result; &#125;else &#123; return result; &#125;&#125;// 递归思路public double Power1(double base, int expone if (base == 0 )&#123; return 0; &#125; if (exponent == 0)&#123; return 1; &#125; double result = 0.0; int n = Math.abs(exponent); result = Power1(base,n &gt;&gt; 1); result = result * result; if ((n &amp; 1) == 1)&#123; // 如果指数n为奇数，则要再乘一次底数base result = result * base; &#125; if (exponent &lt; 0)&#123; // 如果指数为负数，则应该求result的倒数 result = 1.0/result; &#125; return result;&#125;","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 二进制中 1 的个数","slug":"剑指offer题解-二进制中-1-的个数","date":"2019-09-23T14:57:00.000Z","updated":"2019-09-24T14:22:21.274Z","comments":true,"path":"2019/09/23/剑指offer题解-二进制中-1-的个数/","link":"","permalink":"http://suiyia.github.io/2019/09/23/剑指offer题解-二进制中-1-的个数/","excerpt":"","text":"题目描述输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。解题想法位比较思路1：使用整数右移与 1 进行位比较，计算总个数。但是如果是负数，高位右移将会补 1，所以可以使用 &gt;&gt;&gt; 无符号右移或者将负数变为正数再进行右移。使用 1 左移的方式进行位比较，一直比较到 Interger.MAX_VALUE = 0x7fffffff思路2：如果一个整数不为 0，那么这个整数至少有一位是 1。如果我们把这个整数减 1，那么原来处在整数最右边的 1 就会变为 0，1 右边的 0 变为 1。其余所有位将不会受到影响。然后将两者相与，如果结果不为 0，说明原来整数最右边 1 的左边里面肯定包含 1，然后减 1 继续这么循环下去，不为 0 的次数就是 1 出现的次数。例：1100 &amp; 1011 = 1000，数字 1100 最右边的 1 左边还有一个 1代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 先变为正整数public int NumberOf12(int n) &#123; if (n == 0)&#123; return 0; &#125; int count = 0; if (n &lt; 0)&#123; n = n &amp; 0x7fffffff; count ++; &#125; while (n != 0)&#123; if ((n &amp; 1) != 0)&#123; count++; &#125; n = n &gt;&gt; 1; &#125; return count;&#125;// 整数无符号右移public int NumberOf13(int n) &#123; if (n == 0)&#123; return 0; &#125; int count = 0; while (n != 0)&#123; if ((n &amp; 1) != 0)&#123; count++; &#125; n = n &gt;&gt;&gt; 1; &#125; return count;&#125;// 1 左移public int NumberOf1(int n) &#123; if (n == 0)&#123; return 0; &#125; int count = 0; int flag = 1; while (flag != 0)&#123; if (flag &amp; n == 1)&#123; count ++; &#125; flag = flag &lt;&lt; 1; &#125; return flag;&#125;// 思路 2public int NumberOf11(int n) &#123; if (n == 0)&#123; return 0; &#125; int count = 0; while (n != 0)&#123; count ++; n = n &amp; (n-1); &#125; return count;&#125;","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 矩形覆盖","slug":"剑指offer题解-矩形覆盖","date":"2019-09-23T14:49:00.000Z","updated":"2019-09-23T14:57:02.886Z","comments":true,"path":"2019/09/23/剑指offer题解-矩形覆盖/","link":"","permalink":"http://suiyia.github.io/2019/09/23/剑指offer题解-矩形覆盖/","excerpt":"","text":"题目描述我们可以用21的小矩形横着或者竖着去覆盖更大的矩形。请问用n个21的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？解题想法实质是斐波拉契数列代码实现12345678// 递归版本 public int RectCover(int target) &#123; if (n == 1) return 1; if (n == 2) return 2; return RectCover(n - 1) + RectCover(n - 2) * 2; &#125;注意点","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 变态跳台阶","slug":"剑指offer题解-变态跳台阶","date":"2019-09-23T13:52:00.000Z","updated":"2019-09-23T14:49:00.226Z","comments":true,"path":"2019/09/23/剑指offer题解-变态跳台阶/","link":"","permalink":"http://suiyia.github.io/2019/09/23/剑指offer题解-变态跳台阶/","excerpt":"","text":"题目描述一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法解题想法参考前面的斐波拉契数列第 n 层台阶可能由：第 n-1 跳一阶过来，还可能由第 n-2 跳两阶过来等，所以总情况 f（n）= f（n-2）+ f（n-1）+ … + f(1)递推关系式实现 f（n）= 2 * f（n-1）代码实现12345678910111213141516171819202122232425262728// 递归版本public int Fibonacci(int n) &#123; if (n == 0)&#123; return 0; &#125; if (n == 1)&#123; return 1; &#125; return 2 * Fibonacci(n-1);&#125; // 循环public int Fibonacci23(int n)&#123; if (n == 0)&#123; return 0; &#125; if (n == 1)&#123; return 1; &#125; int b = 1; int c = 0; for (int i = 1;i&lt;n;i++)&#123; c = 2 * b; b = c; &#125; return c;&#125;注意点","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 跳台阶","slug":"剑指offer题解-跳台阶","date":"2019-09-23T13:15:00.000Z","updated":"2019-09-23T13:51:57.234Z","comments":true,"path":"2019/09/23/剑指offer题解-跳台阶/","link":"","permalink":"http://suiyia.github.io/2019/09/23/剑指offer题解-跳台阶/","excerpt":"","text":"题目描述一只青蛙一次可以跳上 1 级台阶，也可以跳上 2 级。求该青蛙跳上一个 n 级的台阶总共有多少种跳法（先后次序不同算不同的结果）。解题想法第 n 层台阶可能由：第 n-1 跳一阶过来，还可能由第 n-2 跳两阶过来，所以总情况 f（n）= f（n-2）+ f（n-1）其实就是斐波拉契数列代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243// 递归版本public int Fibonacci(int n) &#123; if (n == 0)&#123; return 0; &#125; if (n == 1)&#123; return 1; &#125; return Fibonacci(n-1) + Fibonacci(n-2);&#125; // 循环public int Fibonacci23(int n)&#123; if (n == 0)&#123; return 0; &#125; if (n == 1 || n == 2)&#123; return 1; &#125; int a = 0; int b = 1; int c = 0; for (int i = 1;i&lt;n;i++)&#123; c = a + b; a = b; b = c; &#125; return c;&#125;// 多项式递推public int Fibonacci2(int n) &#123; if(n==0) &#123; return 0; &#125; else if(n==1||n==2) &#123; return 1; &#125; else if(n==3) &#123; return 2; &#125; else &#123; return 3*Fibonacci(n-3)+2*Fibonacci(n-4); &#125;&#125;注意点","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 斐波拉契数列","slug":"剑指offer题解-斐波拉契数列","date":"2019-09-23T12:39:00.000Z","updated":"2019-09-23T13:14:37.538Z","comments":true,"path":"2019/09/23/剑指offer题解-斐波拉契数列/","link":"","permalink":"http://suiyia.github.io/2019/09/23/剑指offer题解-斐波拉契数列/","excerpt":"","text":"题目描述大家都知道斐波那契数列，现在要求输入一个整数 n，请你输出斐波那契数列的第 n 项（从 0 开始，第 0 项为 0）。n&lt;=39解题想法递归，f（n）= f（n-1）+ f（n-2），但是每一次的迭代计算结果没有保存，很容易栈溢出循环方式，每次的结果进行累加多项关系式递推代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243// 递归版本public int Fibonacci(int n) &#123; if (n == 0)&#123; return 0; &#125; if (n == 1)&#123; return 1; &#125; return Fibonacci(n-1) + Fibonacci(n-2);&#125; // 循环public int Fibonacci23(int n)&#123; if (n == 0)&#123; return 0; &#125; if (n == 1 || n == 2)&#123; return 1; &#125; int a = 0; int b = 1; int c = 0; for (int i = 1;i&lt;n;i++)&#123; c = a + b; a = b; b = c; &#125; return c;&#125;// 多项式递推public int Fibonacci2(int n) &#123; if(n==0) &#123; return 0; &#125; else if(n==1||n==2) &#123; return 1; &#125; else if(n==3) &#123; return 2; &#125; else &#123; return 3*Fibonacci(n-3)+2*Fibonacci(n-4); &#125;&#125;注意点","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[]},{"title":"剑指offer题解 | 旋转数组的最小数字","slug":"剑指offer题解-旋转数组的最小数字","date":"2019-09-19T15:27:00.000Z","updated":"2019-09-23T12:39:25.513Z","comments":true,"path":"2019/09/19/剑指offer题解-旋转数组的最小数字/","link":"","permalink":"http://suiyia.github.io/2019/09/19/剑指offer题解-旋转数组的最小数字/","excerpt":"","text":"题目描述把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。解题想法常规思路：从头到尾遍历一遍找到最小值，时间复杂度 O（N）方法二非递减数组旋转，旋转之后可以看做是两个非递减数组的拼接，当 a[index] &gt; a[index+1] 时，最小值就是 a[index+1]。有序数组的查找，可以选择二分查找规律（数组内元素都不相同）：若 A[mid] &gt; a[low]，那么最小值一定在 mid 及 high 之间；若 A[mid] &lt; a[low]，那么最小值一定在 low 及 mid 之间注意点：如果 A[mid] = a[low]，那么就不能判断最小值在哪一个位置。例如 01111 旋转可以变为 11110 和 10111。只能从头到尾遍历代码实现方法二实现123456789101112131415161718192021222324252627282930313233343536373839404142public int minNumberInRotateArray(int [] array) &#123; if (array.length == 0)&#123; return 0; &#125; if (array.length == 1)&#123; return array[0]; &#125; int low = 0; int high = array.length - 1; while(low &lt; high)&#123; int mid = (low + high) / 2; if (low == high -1)&#123; return array[high]; &#125; if (array[mid] &gt; array[low])&#123; // 最小值在右边 low = mid; &#125;else if (array[mid] &lt; array[low])&#123; // 最小值在左边 high = mid; &#125;else &#123; // 分辨不出最小值位置 return serach(array); &#125; &#125; return -1;&#125; // 从头到尾查找一遍 public int serach(int[] array)&#123; int minValue = Integer.MAX_VALUE; for (int i = 0; i &lt; array.length; i++) &#123; if (array[i] &lt; minValue)&#123; minValue = array[i]; &#125; &#125; return minValue;&#125;注意点数组为空，或者只有一个长度的情况，考虑数组边界问题","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[]},{"title":"剑指offer题解 | 两个栈实现队列","slug":"剑指offer题解-两个栈实现队列","date":"2019-09-19T13:13:00.000Z","updated":"2019-09-19T15:13:51.892Z","comments":true,"path":"2019/09/19/剑指offer题解-两个栈实现队列/","link":"","permalink":"http://suiyia.github.io/2019/09/19/剑指offer题解-两个栈实现队列/","excerpt":"","text":"题目描述用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。时间限制：1秒 空间限制：32768K解题想法方法 1（常规思路，移动次数较多）stack1 专门用于 push 数据，stack2 专门 pop 数据。调用 pop() 方法时候，stack1 数据全部 push 到 stack2，保存 stack2 最顶上元素。pop 方法结束之前，将 stack2 的数据再推回到 stack1 中。方法 2（推荐，移动次数少）stack1 专门用于 push 数据。pop 方法调用的时候，若 stack2 为空就先将 stack1 中的全部数据推到 stack2，然后 pop stack2 中的元素；否则直接 pop stack2 中的数据。代码实现方法二123456789101112131415161718Stack&lt;Integer&gt; stack1 = new Stack&lt;Integer&gt;(); Stack&lt;Integer&gt; stack2 = new Stack&lt;Integer&gt;(); public void push(int node) &#123; stack1.push(node); &#125; public int pop() &#123; if (stack1.isEmpty() &amp;&amp; stack2.isEmpty())&#123; throw new RuntimeException(&quot;Empty exception!&quot;); &#125; if (stack2.isEmpty())&#123; while (!stack1.isEmpty())&#123; stack2.push(stack1.pop()); &#125; &#125; return stack2.pop(); &#125;注意点pop 数据考虑边界情况，栈为空","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 重建二叉树","slug":"剑指Offer题解-重建二叉树","date":"2019-09-18T14:32:00.000Z","updated":"2019-09-19T15:13:51.912Z","comments":true,"path":"2019/09/18/剑指Offer题解-重建二叉树/","link":"","permalink":"http://suiyia.github.io/2019/09/18/剑指Offer题解-重建二叉树/","excerpt":"","text":"题目描述输入一个链表，按链表从尾到头的顺序返回一个ArrayList。时间限制：1秒 空间限制：32768K解题想法方法 1. 使用栈保存遍历链表的结果，然后 push 栈输出到 ArrayList方法 2. 递归方式实现倒序输出代码实现递归方式实现12345678910111213141516171819ArrayList&lt;Integer&gt; arrayList=new ArrayList&lt;Integer&gt;(); public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; if (listNode != null)&#123; printListFromTailToHead(listNode.next); arrayList.add(listNode.val); &#125; return arrayList; &#125; class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125; &#125;","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 从尾到头打印链表","slug":"剑指Offer题解-从尾到头打印链表","date":"2019-09-17T15:18:00.000Z","updated":"2019-09-19T15:13:51.901Z","comments":true,"path":"2019/09/17/剑指Offer题解-从尾到头打印链表/","link":"","permalink":"http://suiyia.github.io/2019/09/17/剑指Offer题解-从尾到头打印链表/","excerpt":"","text":"题目描述输入一个链表，按链表从尾到头的顺序返回一个ArrayList。时间限制：1秒 空间限制：32768K解题想法方法 1. 使用栈保存遍历链表的结果，然后 push 栈输出到 ArrayList方法 2. 递归方式实现倒序输出代码实现递归方式实现12345678910111213141516171819ArrayList&lt;Integer&gt; arrayList=new ArrayList&lt;Integer&gt;(); public ArrayList&lt;Integer&gt; printListFromTailToHead(ListNode listNode) &#123; if (listNode != null)&#123; printListFromTailToHead(listNode.next); arrayList.add(listNode.val); &#125; return arrayList; &#125; class ListNode &#123; int val; ListNode next = null; ListNode(int val) &#123; this.val = val; &#125; &#125;","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 替换空格","slug":"替换空格-剑指Offer","date":"2019-09-17T13:31:00.000Z","updated":"2019-09-19T15:13:51.870Z","comments":true,"path":"2019/09/17/替换空格-剑指Offer/","link":"","permalink":"http://suiyia.github.io/2019/09/17/替换空格-剑指Offer/","excerpt":"","text":"题目描述请实现一个函数，将一个字符串中的每个空格替换成“%20”。例如，当字符串为We Are Happy.则经过替换之后的字符串为We%20Are%20Happy。时间限制：1秒 空间限制：32768K解题想法不使用工具类思路：先统计空格出现次数，然后就知道了替换后的字符串长度，使用另外的字符串数组保存替换后的字符串，然后从右往左进行填充代码实现先统计空格出现的次数，出现一次空格，那么增加的长度就是加 2，N 个空格就是增加了 N*2然后用另外的数组保存替换后的字符12345678910111213141516171819202122232425262728293031public static String replaceSpace(StringBuffer str) &#123; // 统计空格数量 int spaceCount = 0; for (int i = 0; i &lt; str.length(); i++) &#123; if (str.charAt(i) == &apos; &apos;)&#123; spaceCount++; &#125; &#125; int length = str.length(); // 用另外的字符数组保存字符 char[] a = new char[length + spaceCount * 2]; // 字符数组索引，从最后面开始 int afterIndex = length + spaceCount * 2 - 1; for (int j = length - 1; j &gt;= 0; j--) &#123; if (str.charAt(j) != &apos; &apos;)&#123; // 如果不是空格，就直接赋值，索引也跟着减 a[afterIndex] = str.charAt(j); afterIndex --; &#125;else &#123; a[afterIndex] = &apos;0&apos;; a[afterIndex - 1] = &apos;2&apos;; a[afterIndex - 2] = &apos;%&apos;; afterIndex = afterIndex - 3; &#125; &#125; return String.valueOf(a); &#125;注意点从后往前填充相对简单点","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"剑指offer题解 | 二维数组中的查找 ","slug":"二维数组中的查找-剑指Offer","date":"2019-09-16T15:11:00.000Z","updated":"2019-09-19T15:11:08.513Z","comments":true,"path":"2019/09/16/二维数组中的查找-剑指Offer/","link":"","permalink":"http://suiyia.github.io/2019/09/16/二维数组中的查找-剑指Offer/","excerpt":"","text":"题目描述在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。时间限制：1秒 空间限制：32768K解题想法常规思路：左上角开始，每行从左到右都轮询一次。时间复杂度 O（N^2）空间复杂度 O（1）从右下角开始，每行从左往右轮询：上面一行相同列的元素比当前元素小，右边同行元素比当前元素大，那么不用全部元素比较。时间复杂度：O(行高 + 列宽)空间复杂度：O(1)从右上角开始，从右往左。原理同上从右下角开始，和常规思路类似代码实现M 行 N 列数组，寻找元素 K左下角开始寻找123456789101112131415public static boolean Find(int target, int [][] array) &#123; int i = array.length - 1; int j = 0; while (i &gt;= 0 &amp;&amp; j &lt; array[0].length)&#123; if (array[i][j] &gt; target) &#123; i--; &#125;else if(array[i][j] &lt; target)&#123; j++; &#125;else &#123; return true; &#125; &#125; return false;&#125;注意点数组边界问题常规思路，遇到有序序列进行查找时，可以使用二分查找，时间复杂度将进一步降低，时间复杂度 Mlog(n)","categories":[{"name":"剑指offer","slug":"剑指offer","permalink":"http://suiyia.github.io/categories/剑指offer/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://suiyia.github.io/tags/算法/"}]},{"title":"日志框架学习及Log4j 2 概念整理","slug":"Log4j-2-基本概念","date":"2019-09-04T06:52:00.000Z","updated":"2019-10-02T02:27:36.963Z","comments":true,"path":"2019/09/04/Log4j-2-基本概念/","link":"","permalink":"http://suiyia.github.io/2019/09/04/Log4j-2-基本概念/","excerpt":"","text":"日志框架分类日志框架按照功能可以分为日志接口、日志实现两部分。编写程序时，推荐使用日志接口的 API 进行方法调用，然后使用对应的日志实现框架打印日志。常用日志框架的使用方式为： Log4j2-api（接口） + Log4j2-core（实现）。SLF4J（接口）+ 其它日志框架实现。日志接口，日志的接口规范，它对用户提供了统一的日志接口，屏蔽了不同日志组件的差异。Apache Commons Logging Component，2014 年之后文档没有再更新SLF4J（Simple Logging Facade for Java），定义了各种日志框架（java.util.logging, logback, log4j 等）的抽象，是 Java 日志输出的标准接口。需引入 slf4j-api-xxx.jarslf4j-api 不同版本是互相兼容的，不同系统之间的 slf4j-api 版本不同并不会造成冲突；但是其实现类是可能存在冲突的，例如使用 slf4j-api-1.0.jar 和 slf4j-simple-1.0.jar 是没有问题的，但是使用 slf4j-simple-2.0.jar 可能存在问题。在引入相关依赖的时候，要保证 slf4j-api 的版本和其实现日志框架的版本一致！Log4J2 api，log4j 2-api 包和 slf4J 类似，定义日志输出接口规范，具体日志输出形式根据依赖的日志实现 jar 包确定日志实现，定义具体日志打印内容JDKLog，java.util.logging.Logger，jdk 自带的日志工具类，它通过 getLogger 获取日志对象、setLevel 定义日志级别、Handler 定义日志输出方式 （输出到文件、控制台、网络流）、Formatter 定义日志输出样式。需引入 slf4j-jdk14-xxx.jarLOGBack，继承于 Log4J，官网表示它可作为 log4j 的 successor（继承者），比 log4j 更好！它包括 3 个模块：logback-core，下面两个模块的基础依赖logback-classic，对 log4j 进行了显著地改进，实现了 SLF4J API，方便随时切换日志框架。logback-access，与 Servlet 容器（Tomcat、Jetty）进行集成，提供 HTTP 访问日志功能。Log4J，2015 年开始已经停止维护Log4J2 core Log4J 升级版，2019-08-06 版本更新至 2.12.1，API 相关用法不兼容 1.X 版本Log4j 2 内置概念Markers：为某条日志添加标志位，使用 %marker 进行输出1234567891011121314public void test()&#123; private static final Marker SQL_MARKER = MarkerManager.getMarker(&quot;SQL&quot;); Marker markerA = MarkerManager.getMarker(&quot;Marker A&quot;); Marker markerB = MarkerManager.getMarker(&quot;Marker B&quot;); logger.debug(markerA,&quot;your name is &#123;&#125; &quot;,&quot;Jack&quot;); logger.debug(markerB,&quot;your name is &#123;&#125; &quot;,&quot;Ma&quot;);&#125;log4j.xml：&lt;PatternLayout pattern=&quot;%d&#123;HH:mm:ss.SSS&#125; %-5level %class&#123;36&#125; %L %M %marker - %msg%xEx%n&quot;/&gt;Console Out：10:14:02.639 DEBUG FlowTracing 60 test Marker A - your name is Jack 10:14:02.642 DEBUG FlowTracing 61 test Marker B - your name is MaLookups：在配置文件中添加变量、使用变量Appenders：定义日志事件输出方式（日志文件名称、路径、什么级别日志才能输出、文件大小等等），其实就是文件流输出定义。AsyncAppender 用另外的线程记录日志，默认使用 ArrayBlockingQueue 队列进行日志记录，当发生异常时，默认会忽略异常，记得手动开启，并使用FailoverAppender 对异常情况进行补充打印输出ConsoleAppender，控制台输出FailoverAppender，当主 Appender 失败时，它将起作用FileAppender，文件输出，当多个程序对同一文件进行输出时，各自程序之间的配置也不受影响JDBCAppender，直接写到数据库HttpAppender，http 请求发送到另外的服务接收，如果服务返回的不是 2XX，将会抛出异常。KafkaAppender，发送到 KafkaRollingFileAppender，可以滚动的文件输出，包含触发规则（触发滚动条件：时间、大小）、滚动规则（怎么进行更新：文件数量），默认日志文件个数为 7 个。等等Layouts：Appender 使用定义好的 LayOut 对 LogEvent 进行格式化输出，CSV Layouts，以 Comma Separated Value (CSV) 形式输出JSON Layout，JSON 格式输出Pattern Layout，用特殊的字符输出对应的内容，定制化强XML LayoutLocation Infomation，当日志中需要日志所在类、方法、代码行数这些信息时，会花费 1.3-5 倍的时间，相比不需要 Location Infomation 的场景。并且在使用异步的 Appender 时，默认的 Location Infomation 默认关闭，如果开启，会比不开启花费 30-100 倍的性能消耗Filters：决定哪些事件可以输出，哪些事件不能输出。过滤结果有 3 个结果，ACCEPT（允许）, DENY（拒绝输出）or NEUTRAL（中立、默认）。BurstFilter，当每秒日志输出事件速率大于一定值，将会抛弃掉级别低的日志CompositeFilter，直接在 configuration 级别添加多个过滤器DynamicThresholdFilter，根据一些属性值去动态修改该条日志的输出级别MapFilter，如果 LogEvent 中的 MapMessage 内包含特定属性，就可以选择过滤MarkerFilter、NoMarkerFilter，对应定义或者未定义 Marker 的事件进行过滤RegexFilter，正则过滤 formatted or unformatted messageThreadContextMapFilter ，对 ThreadContextMap 中的内容进行过滤ThresholdFilter，对 Level 进行过滤TimeFilter，根据某个时间点、时间段进行过滤3. Log4J 2 Java API 用法Flow Tracing日志跟踪Markers（标记）对于有特定标识需求的地方，可以使用 Marker 进行标记，并且用 %marker 进行打印输出。ThreadContextMapped Diagnostic Context（MDC）的实现，类似 request，可以存放 key-value 键值对，也可以销毁，使用 %X{key} 输出。the MDC is a map which stores the context data of the particular thread where the context is running.12345678910%X&#123;id&#125; 输出 context map 中 key = id 的值%X 输出 context map 所有值public void test()&#123; ThreadContext.put(&quot;id&quot;, &quot;321&quot;); // Add the fishtag; ThreadContext.put(&quot;name&quot;, &quot;996&quot;); // Add the fishtag; logger.debug(&quot;Message 1&quot;); logger.debug(&quot;Message 2&quot;); ThreadContext.clearAll();&#125;其他log4j-slf4j-impl 是 slf4j 转接到 log4j 2 的日志输出框架。slf4j-log4j12 是 slf4j 转接到 log4j 1.x 的日志输出框架 ，而 log4j 1.x 已经在 2015 年 8 月就停止更新了。log4j 官方建议升级到 log4j 2","categories":[],"tags":[{"name":"Log4j","slug":"Log4j","permalink":"http://suiyia.github.io/tags/Log4j/"}]},{"title":"浮点数整数转换精度丢失问题","slug":"浮点数整数转换精度丢失问题","date":"2019-08-10T09:44:00.000Z","updated":"2019-09-19T10:36:57.304Z","comments":true,"path":"2019/08/10/浮点数整数转换精度丢失问题/","link":"","permalink":"http://suiyia.github.io/2019/08/10/浮点数整数转换精度丢失问题/","excerpt":"","text":"浮点数转换精度丢失在线支付对接，支付商（微信、支付宝、银联等）的接口中，定义的金额单位不一样，有时候需要对分、元进行相互转换，转换的过程中容易出现问题。下面的例子，系统中接收的参数是元，请求接口单位是分，在转换过程中出现精度丢失，少扣了用户 1 分钱。1234567public class Main &#123; public static void main(String[] args) &#123; System.out.println((int) (0.29*100)); &#125;&#125;输出： 28错误原因0.29*100 = 28.999999999999996…浮点数强制转换成整数类型会舍弃非整数部分解决方法(int) Math.round(0.29*100) -&gt; 29浮点数大小比较错误12345678910// 例子 1System.out.println(0.1d == 0.1f); // false// 例子 2System.out.println(10.222222225f == 10.222222229f); // trueSystem.out.println(10.222222225f &gt; 10.222222229f); // falseSystem.out.println(10.222222225f &lt; 10.222222229f); // false// 例子 3Double a = Double.valueOf(&quot;0.0&quot;);Double b = Double.valueOf(&quot;-0.0&quot;);System.out.println(a.equals(b)); // false浮点数由于精度问题，并不能用 ==，&gt;，&lt; 来进行大小比较，最好的方式就是定义一个精度，用差的绝对值比较，在精度范围内就认为是相等的官方文档参考Java中的浮点数比较 == equals 和 compare","categories":[],"tags":[{"name":"浮点数","slug":"浮点数","permalink":"http://suiyia.github.io/tags/浮点数/"}]},{"title":"Springboot 项目运用 Redis 缓存数据","slug":"Springboot-项目运用-Redis-缓存数据","date":"2019-08-10T09:40:00.000Z","updated":"2019-08-10T09:51:13.059Z","comments":true,"path":"2019/08/10/Springboot-项目运用-Redis-缓存数据/","link":"","permalink":"http://suiyia.github.io/2019/08/10/Springboot-项目运用-Redis-缓存数据/","excerpt":"","text":"介绍Springboot 项目与 Redis 结合获取数据pom 依赖主要是 mybatis、redis 的相关依赖12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748server: servlet: context-path: /web port: 8080spring: datasource: druid: # 数据库访问配置, 使用druid数据源 type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/test?useunicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=UTC username: root password: 123456 # 连接池配置 initial-size: 5 min-idle: 5 max-active: 20 # 连接等待超时时间 max-wait: 30000 # 配置检测可以关闭的空闲连接间隔时间 time-between-eviction-runs-millis: 60000 # 配置连接在池中的最小生存时间 min-evictable-idle-time-millis: 300000 validation-query: select &apos;1&apos; from dual test-while-idle: true test-on-borrow: false test-on-return: false # 打开PSCache，并且指定每个连接上PSCache的大小 pool-prepared-statements: true max-open-prepared-statements: 20 max-pool-prepared-statement-per-connection-size: 20 # 配置监控统计拦截的filters, 去掉后监控界面sql无法统计, &apos;wall&apos;用于防火墙 filters: stat,wall # Spring监控AOP切入点，如x.y.z.service.*,配置多个英文逗号分隔 aop-patterns: com.springboot.servie.* redis: # Redis数据库索引（默认为0） database: 0 # Redis服务器地址 host: localhost # Redis服务器连接端口 port: 6379logging: level: com.example.demo.dao: debugRedis 配置类12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Configurationpublic class RedisConfig extends CachingConfigurerSupport &#123; // 自定义缓存key生成策略 @Override @Bean public KeyGenerator keyGenerator() &#123; return new KeyGenerator() &#123; @Override public Object generate(Object target, java.lang.reflect.Method method, Object... params) &#123; StringBuffer sb = new StringBuffer(); sb.append(target.getClass().getName()); sb.append(method.getName()); for (Object obj : params) &#123; sb.append(obj.toString()); &#125; return sb.toString(); &#125; &#125;; &#125; // 缓存管理器 @Bean public CacheManager cacheManager(RedisConnectionFactory connectionFactory) &#123; RedisCacheManager cacheManager = RedisCacheManager.create(connectionFactory); return cacheManager; &#125; @Bean public RedisTemplate&lt;String, String&gt; redisTemplate(RedisConnectionFactory factory) &#123; StringRedisTemplate template = new StringRedisTemplate(factory); setSerializer(template);// 设置序列化工具 template.afterPropertiesSet(); return template; &#125; private void setSerializer(StringRedisTemplate template) &#123; @SuppressWarnings(&#123; &quot;rawtypes&quot;, &quot;unchecked&quot; &#125;) Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); template.setValueSerializer(jackson2JsonRedisSerializer); &#125;&#125;dao 层以及实现使用 MyBatis 注解方式实现数据访问123456789101112131415@Mapperpublic interface StudentManager &#123; @Update(&quot;update student set sname=#&#123;sname&#125;,ssex=#&#123;ssex&#125; where sno=#&#123;sno&#125;&quot;) int update(Student student); @Delete(&quot;delete from student where sno=#&#123;sno&#125;&quot;) void deleteStudentBySno(String sno); @Select(&quot;select * from student where sno=#&#123;sno&#125;&quot;) @Results(id = &quot;student&quot;, value = &#123; @Result(property = &quot;sno&quot;, column = &quot;sno&quot;, javaType = String.class), @Result(property = &quot;sname&quot;, column = &quot;sname&quot;, javaType = String.class), @Result(property = &quot;ssex&quot;, column = &quot;ssex&quot;, javaType = String.class) &#125;) Student queryStudentBySno(String sno);&#125;service 层及实现queryStudentBySno 方法使用了注解 @Cacheable(key=”#p0”)，即将 id 作为 redis 中的 key 值@CacheConfig(cacheNames = “student”) 一个类中可能会有多个缓存操作，而这些缓存操作可能是重复的@Cacheable 是用来声明方法是可缓存的@CachePut 主要用于数据新增和修改操作上@CacheEvict 通常用在删除方法上，用来从缓存中移除相应数据123456789101112131415161718192021222324252627282930313233343536@CacheConfig(cacheNames = &quot;student&quot;)public interface StudentService &#123; @CachePut(key = &quot;#p0.sno&quot;) Student update(Student student); @CacheEvict(key = &quot;#p0&quot;, allEntries = true) void deleteStudentBySno(String sno); @Cacheable(key = &quot;#p0&quot;) Student queryStudentBySno(String sno);&#125;@Servicepublic class StudentServiceImpl implements StudentService &#123; @Autowired private StudentManager studentManager; @Override public Student update(Student student) &#123; this.studentManager.update(student); return this.studentManager.queryStudentBySno(student.getSno()); &#125; @Override public void deleteStudentBySno(String sno) &#123; this.studentManager.deleteStudentBySno(sno); &#125; @Override public Student queryStudentBySno(String sno) &#123; return this.studentManager.queryStudentBySno(sno); &#125;&#125;Test 用例第一次从数据库中读取，第二次直接从缓存读取123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTestpublic class DemoApplicationTests &#123; @Autowired private StudentService studentService; @Test public void contextLoads() &#123; System.out.println(studentService.queryStudentBySno(&quot;001&quot;).toString()); System.out.println(studentService.queryStudentBySno(&quot;001&quot;).toString()); &#125;&#125;2019-08-10 17:27:32.739 DEBUG 7140 --- [ main] c.e.d.d.S.queryStudentBySno : ==&gt; Preparing: select * from student where sno=? 2019-08-10 17:27:33.053 DEBUG 7140 --- [ main] c.e.d.d.S.queryStudentBySno : ==&gt; Parameters: 001(String)2019-08-10 17:27:33.108 DEBUG 7140 --- [ main] c.e.d.d.S.queryStudentBySno : &lt;== Total: 1Student(sno=001, sname=KangKang, ssex=M )Student(sno=001, sname=KangKang, ssex=M )总结","categories":[{"name":"Spring学习","slug":"Spring学习","permalink":"http://suiyia.github.io/categories/Spring学习/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://suiyia.github.io/tags/Redis/"},{"name":"Springboot","slug":"Springboot","permalink":"http://suiyia.github.io/tags/Springboot/"}]},{"title":"Springboot 与 AOP 实现","slug":"Springboot-与-AOP-实现","date":"2019-08-10T09:39:00.000Z","updated":"2019-08-10T09:51:13.073Z","comments":true,"path":"2019/08/10/Springboot-与-AOP-实现/","link":"","permalink":"http://suiyia.github.io/2019/08/10/Springboot-与-AOP-实现/","excerpt":"","text":"介绍Springboot 项目 AOP 实现，记录方法的执行过程pom 依赖druid、JdbcTemplate、aop123456789101112131415161718192021222324252627282930313233343536373839&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;代码实现Mysql 脚本12345678910CREATE TABLE SYS_LOG ( ID INT(20) NOT NULL COMMENT &apos;用户名&apos; PRIMARY KEY AUTO_INCREMENT , USERNAME VARCHAR(50) NULL COMMENT &apos;用户名&apos;, OPERATION VARCHAR(50) NULL COMMENT &apos;用户操作&apos;, TIME INT(11) NULL COMMENT &apos;响应时间&apos;, METHOD VARCHAR(1024) NULL COMMENT &apos;请求方法&apos;, PARAMS VARCHAR(1024) NULL COMMENT &apos;请求参数&apos;, IP VARCHAR(64) NULL COMMENT &apos;IP地址&apos;, CREATE_TIME DATE NULL COMMENT &apos;创建时间&apos;);实体类123456789101112131415161718192021import java.io.Serializable;import java.util.Date;import lombok.Getter;import lombok.Setter;import lombok.ToString;@Setter@Getter@ToStringpublic class SysLog implements Serializable &#123; private Integer id; private String username; private String operation; private Integer time; private String method; private String params; private String ip; private Date createTime;&#125;定义一个方法级别的 @Log 注解，需要监控的方法加上该注解就行12345@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface Log &#123; String value() default &quot;&quot;;&#125;定义 dao 方法，保存日志到数据库123public interface SysLogDao &#123; void saveSysLog(SysLog sysLog);&#125;1234567891011121314151617@Componentpublic class SysLogDaoImpl implements SysLogDao &#123; @Autowired private JdbcTemplate jdbcTemplate; @Override public void saveSysLog(SysLog sysLog) &#123; StringBuffer sql = new StringBuffer(&quot;insert into sys_log &quot;); sql.append(&quot;(username,operation,time,method,params,ip,create_time) &quot;); sql.append(&quot;values(:username,:operation,:time,:method,&quot;); sql.append(&quot;:params,:ip,:createTime)&quot;); NamedParameterJdbcTemplate npjt = new NamedParameterJdbcTemplate(this.jdbcTemplate.getDataSource()); npjt.update(sql.toString(), new BeanPropertySqlParameterSource(sysLog)); &#125;&#125;切面切点定义1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889@Aspect@Componentpublic class LogAspect &#123; @Autowired private SysLogDao sysLogDao; @Pointcut(&quot;@annotation(com.example.demo.annotion.Log)&quot;) public void pointcut()&#123;&#125; @Around(&quot;pointcut()&quot;) public Object around(ProceedingJoinPoint proceedingJoinPoint)&#123; Object result = null; long beginTime = System.currentTimeMillis(); try &#123; // 执行方法 result = proceedingJoinPoint.proceed(); &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; // 执行时长(毫秒) long time = System.currentTimeMillis() - beginTime; // 保存日志 saveLog(proceedingJoinPoint, time); return result; &#125; private void saveLog(ProceedingJoinPoint joinPoint, long time) &#123; MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); SysLog sysLog = new SysLog(); Log logAnnotation = method.getAnnotation(Log.class); if (logAnnotation != null) &#123; // 注解上的描述 sysLog.setOperation(logAnnotation.value()); &#125; // 请求的方法名 String className = joinPoint.getTarget().getClass().getName(); String methodName = signature.getName(); sysLog.setMethod(className + &quot;.&quot; + methodName + &quot;()&quot;); // 请求的方法参数值 Object[] args = joinPoint.getArgs(); // 请求的方法参数名称 LocalVariableTableParameterNameDiscoverer u = new LocalVariableTableParameterNameDiscoverer(); String[] paramNames = u.getParameterNames(method); if (args != null &amp;&amp; paramNames != null) &#123; String params = &quot;&quot;; for (int i = 0; i &lt; args.length; i++) &#123; params += &quot; &quot; + paramNames[i] + &quot;: &quot; + args[i]; &#125; sysLog.setParams(params); &#125; // 获取request HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); // 设置IP地址 sysLog.setIp(IPUtils.getIpAddr(request)); // 模拟一个用户名 sysLog.setUsername(&quot;mrbird&quot;); sysLog.setTime((int) time); sysLog.setCreateTime(new Date()); // 保存系统日志 sysLogDao.saveSysLog(sysLog); &#125;&#125;public class IPUtils &#123; /** * 获取IP地址 * * 使用Nginx等反向代理软件， 则不能通过request.getRemoteAddr()获取IP地址 如果使用了多级反向代理的话，X-Forwarded-For的值并不止一个，而是一串IP地址，X-Forwarded-For中第一个非unknown的有效IP字符串，则为真实IP地址 */ public static String getIpAddr(HttpServletRequest request) &#123; String ip = request.getHeader(&quot;x-forwarded-for&quot;); if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getHeader(&quot;Proxy-Client-IP&quot;); &#125; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getHeader(&quot;WL-Proxy-Client-IP&quot;); &#125; if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123; ip = request.getRemoteAddr(); &#125; return &quot;0:0:0:0:0:0:0:1&quot;.equals(ip) ? &quot;127.0.0.1&quot; : ip; &#125;&#125;Controller 方法123456789101112131415161718@RestControllerpublic class TestController &#123; @Log(&quot;执行方法一&quot;) @GetMapping(&quot;/one&quot;) public void methodOne(String name) &#123; &#125; @Log(&quot;执行方法二&quot;) @GetMapping(&quot;/two&quot;) public void methodTwo() throws InterruptedException &#123; Thread.sleep(2000); &#125; @Log(&quot;执行方法三&quot;) @GetMapping(&quot;/three&quot;) public void methodThree(String name, String age) &#123; &#125;&#125;测试12345678910111213http://localhost:8080/web/one?name=KangKanghttp://localhost:8080/web/twohttp://localhost:8080/web/three?name=Mike&amp;age=25&gt; select * from sys_log order by id;ID USERNAME OPERATION TIME METHOD PARAMS IP CREATE_TIME1 mrbird 执行方法一 3 com.example.demo.web.TestController.methodOne() name: KangKang 127.0.0.1 2019-08-102 mrbird 执行方法二 2002 com.example.demo.web.TestController.methodTwo() 127.0.0.1 2019-08-103 mrbird 执行方法三 0 com.example.demo.web.TestController.methodThree() name: Mike age: 25 127.0.0.1 2019-08-104 mrbird 执行方法三 0 com.example.demo.web.TestController.methodThree() name: Mike age: 25 127.0.0.1 2019-08-105 mrbird 执行方法二 2001 com.example.demo.web.TestController.methodTwo() 127.0.0.1 2019-08-10总结切面对项目响应时间的影响待测试，现在用的项目基本没有应用到切面，等有实际落地需求在改进学习下源码","categories":[{"name":"Spring学习","slug":"Spring学习","permalink":"http://suiyia.github.io/categories/Spring学习/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://suiyia.github.io/tags/Springboot/"},{"name":"AOP","slug":"AOP","permalink":"http://suiyia.github.io/tags/AOP/"}]},{"title":"Springboot 使用 MyBatis 实现增删改查","slug":"Springboot-使用-MyBatis-实现增删改查","date":"2019-08-10T09:39:00.000Z","updated":"2019-08-10T09:51:13.110Z","comments":true,"path":"2019/08/10/Springboot-使用-MyBatis-实现增删改查/","link":"","permalink":"http://suiyia.github.io/2019/08/10/Springboot-使用-MyBatis-实现增删改查/","excerpt":"","text":"内容Springboot 项目结合 Mybatis 实现 CRUD 增删改查基本 Mysql 脚本123456789CREATE TABLE student ( sno VARCHAR(10) NOT NULL , sname VARCHAR(10) NOT NULL , ssex VARCHAR(2) NOT NULL );INSERT INTO STUDENT VALUES (&apos;001&apos;, &apos;KangKang&apos;, &apos;M &apos;);INSERT INTO STUDENT VALUES (&apos;002&apos;, &apos;Mike&apos;, &apos;M &apos;);INSERT INTO STUDEN VALUES (&apos;003&apos;, &apos;Jane&apos;, &apos;F &apos;);pom 基本包依赖1234567891011121314151617181920212223&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.16&lt;/version&gt;&lt;/dependency&gt;配置文件 application.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869server: servlet: context-path: /web port: 8080spring: datasource: druid: # 数据库访问配置, 使用druid数据源 type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/test?useunicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=UTC username: root password: 123456 # 连接池配置 initial-size: 5 min-idle: 5 max-active: 20 # 连接等待超时时间 max-wait: 30000 # 配置检测可以关闭的空闲连接间隔时间 time-between-eviction-runs-millis: 60000 # 配置连接在池中的最小生存时间 min-evictable-idle-time-millis: 300000 validation-query: select &apos;1&apos; from dual test-while-idle: true test-on-borrow: false test-on-return: false # 打开PSCache，并且指定每个连接上PSCache的大小 pool-prepared-statements: true max-open-prepared-statements: 20 max-pool-prepared-statement-per-connection-size: 20 # 配置监控统计拦截的filters, 去掉后监控界面sql无法统计, &apos;wall&apos;用于防火墙 filters: stat,wall # Spring监控AOP切入点，如x.y.z.service.*,配置多个英文逗号分隔 aop-patterns: com.springboot.servie.* # WebStatFilter配置 web-stat-filter: enabled: true # 添加过滤规则 url-pattern: /* # 忽略过滤的格式 exclusions: &apos;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&apos; # StatViewServlet配置 stat-view-servlet: enabled: true # 访问路径为/druid时，跳转到StatViewServlet url-pattern: /druid/* # 是否能够重置数据 reset-enable: false # 需要账号密码才能访问控制台 login-username: druid login-password: druid123 # IP白名单 # allow: 127.0.0.1 # IP黑名单（共同存在时，deny优先于allow） # deny: 192.168.1.218 # 配置StatFilter filter: stat: log-slow-sql: truemybatis: mapper-locations: classpath:mapper/*.xml configuration-properties: BEFORE代码实现接口+注解形式实现数据库读取写入1234567891011121314151617181920@Mapperpublic interface StudentManagerWithInject &#123; @Insert(&quot;insert into student(sno,sname,ssex)values(#&#123;sno&#125;,#&#123;name&#125;,#&#123;ssex&#125;)&quot;) int add(Student student); @Update(&quot;update student set sname=#&#123;name&#125;,ssex=#&#123;sex&#125; where sno=#&#123;sno&#125;&quot;) int update(Student student); @Delete(&quot;delete from student where sno=#&#123;sno&#125;&quot;) int deleteBySno(String sno); @Select(&quot;select * from student where sno=#&#123;sno&#125;&quot;) @Results(id = &quot;student&quot;,value= &#123; @Result(property = &quot;sno&quot;, column = &quot;sno&quot;, javaType = String.class), @Result(property = &quot;name&quot;, column = &quot;sname&quot;, javaType = String.class), @Result(property = &quot;sex&quot;, column = &quot;ssex&quot;, javaType = String.class) &#125;) Student queryStudentBySno(String sno);&#125;自动装配实现业务逻辑12345678910111213141516171819202122@RestControllerpublic class TestController &#123; @Autowired private StudentManagerWithInject studentManagerWithInject; @Autowired private StudentMapperWithXML studentMapperWithXML; @RequestMapping(value = &quot;/querystudent&quot;,method = RequestMethod.GET) public Student queryStudentBySno( @RequestParam String sno)&#123; return studentManagerWithInject.queryStudentBySno(sno); &#125; @RequestMapping(value = &quot;/querystudentwithxml&quot;,method = RequestMethod.GET) public Student queryStudentWithXMLBySno( @RequestParam String sno)&#123; return studentMapperWithXML.queryStudentBySno(sno); &#125;&#125;调用接口，得到结果12345678http://localhost:8080/web/querystudent?sno=001输出&#123; &quot;sno&quot;: &quot;001&quot;, &quot;name&quot;: &quot;KangKang&quot;, &quot;sex&quot;: &quot;M &quot;&#125;最后一般项目会增加一个 service 服务层，一个服务可能对应多个数据库操作，这里节省时间就没有加，工作中还是根据项目规范来。学习参考源码第一章节","categories":[{"name":"Spring学习","slug":"Spring学习","permalink":"http://suiyia.github.io/categories/Spring学习/"}],"tags":[{"name":"Springboot","slug":"Springboot","permalink":"http://suiyia.github.io/tags/Springboot/"},{"name":"MyBatis","slug":"MyBatis","permalink":"http://suiyia.github.io/tags/MyBatis/"}]},{"title":"HashMap、HashTable、ConcurrentHashMap 区别","slug":"HashMap、HashTable、ConcurrentHashMap-区别","date":"2019-04-07T06:24:00.000Z","updated":"2019-10-14T02:45:46.478Z","comments":true,"path":"2019/04/07/HashMap、HashTable、ConcurrentHashMap-区别/","link":"","permalink":"http://suiyia.github.io/2019/04/07/HashMap、HashTable、ConcurrentHashMap-区别/","excerpt":"","text":"简单总结 HashMap、Hashtable、ConcurrentHashMap 之间的区别，基于 JDK 1.8.0_191先说结论，暂时有以下几个需要注意的不同点：继承、实现接口不同初始大小、扩容倍数不同线程安全NULL KEY，NULL VALUE 支持不同计算 Hash 值的方式不同1. 继承、实现接口不同12345678public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable &#123;&#125; public class Hashtable&lt;K,V&gt; extends Dictionary&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, java.io.Serializable &#123; public class ConcurrentHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements ConcurrentMap&lt;K,V&gt;, Serializable &#123;HashMap、ConcurrentHashMap 都继承于 AbstractMap 抽象类，但 Hashtable 继承于 Dictionary 抽象类。AbstractMap 实现了 Map 接口，而 Dictionary 没有。这使得 AbstractMap 具有更多的功能，而 Dictionary 逐渐被弃用。2. 初始大小、扩容倍数不同HashMap1234static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16扩容部分代码：newThr = oldThr &lt;&lt; 1; // double thresholdHashtable123456public Hashtable() &#123; this(11, 0.75f);&#125;扩容部分代码：int newCapacity = (oldCapacity &lt;&lt; 1) + 1;ConcurrentHashMap12345/** * The default initial table capacity. Must be a power of 2 * (i.e., at least 1) and at most MAXIMUM_CAPACITY. */private static final int DEFAULT_CAPACITY = 16;初始大小：HashMap、ConcurrentHashMap 都是 16，Hashtable 是 11扩容倍数：HashMap、ConcurrentHashMap 2 倍、Hashtable (2n + 1) 倍。3. 线程安全12345Hashtable:public synchronized V put(K key, V value) &#123;&#125;HashMap:public V put(K key, V value) &#123;&#125;Hashtable 添加元素方法加上了 synchronized 关键字，HashMap 没有，说明 HashMap 不适用于多线程环境。ConcurrentHashMap 添加元素时，只对需要变更的地方加锁。4. NULL KEY，NULL VALUE 支持不同通过观察它们的 put 方法，得到以下结论：Hashtable、ConcurrentHashMap 的 key、value 都不能为 null。HashMap value 可以为 null，而 key 为 null 时，该元素会放在 HashMap 第一位。5. key 的索引计算方法不同计算元素存放位置，会经过两步转化。Object -&gt; int -&gt; index，先将 key 使用 hash 方法转换为一个整数数字，然后对整型数字进行转化，得到这个对象在 map 中的索引。Hashtable12int hash = key.hashCode();int index = (hash &amp; 0x7FFFFFFF) % tab.length;HashMap1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;Hashtable 直接使用对象的 hashCode，然后再使用除留余数法来获得最终的位置。HashMap 在对象的 hashCode 之上，将 hashCode 的高16位和低16位进行异或，得到最终的位置。总结后面学习将对 HashMap，ConcurrentHashMap 源码进行分析总结。ConcurrentHashMap的扩容机制（jdk1.8）HashMap 和Hashtable的区别","categories":[{"name":"Java 基础","slug":"Java-基础","permalink":"http://suiyia.github.io/categories/Java-基础/"}],"tags":[{"name":"集合","slug":"集合","permalink":"http://suiyia.github.io/tags/集合/"}]},{"title":"ArraryList、LinkList和Vector的区别","slug":"ArraryList、LinkList和Vector的区别","date":"2019-03-24T05:53:00.000Z","updated":"2019-10-14T02:45:46.534Z","comments":true,"path":"2019/03/24/ArraryList、LinkList和Vector的区别/","link":"","permalink":"http://suiyia.github.io/2019/03/24/ArraryList、LinkList和Vector的区别/","excerpt":"","text":"本文基于 JDK 1.8.0_1911. 源码对比实现接口类对比扩容机制对比线程安全1.1 实现接口类对比12345678910public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable public class Vector&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable它们都实现 List 接口，说明具备列表的增加、删除、遍历元素等特性。ArrayList、Vector 额外实现 RandomAccess 接口，说明他们能在常量时间复杂度内快速随机访问元素。LinkedList 额外实现 Queue 接口，具备队列的入队、出队等特性。1.2 扩容机制对比ArrayList123456789101112131415private static final int DEFAULT_CAPACITY = 10; // 定义初始大小private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; // 定义列表存储元素数量最大值 private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 现有元素数量 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 增加后元素的数量 = 1 + 0.5 if (newCapacity - minCapacity &lt; 0) // 增加后的元素数量 &lt; 现有的空间，不扩容 newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 增加后的元素数量 &gt; 大于最大值，尝试分配 Integer.MAX_VALUE 个元素，可能会抛出 OutOfMemoryError // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;Vector12345678910111213141516public Vector() &#123; this(10);&#125;protected int capacityIncrement; // 扩容数量值，Vector 初始化不指定时默认为 0private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); // 当扩容数量值小于 0，那么扩容比例为原来的两倍；否则扩容的数量为这个值。 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity);&#125;LinkList1transient int size = 0;初始大小：ArrayList、Vector 默认为 10，LinkList 不指定默认为 0扩容比例：ArrayList 以 1.5 倍进行扩容；Vector 不指定扩容比例时默认为 2 倍进行扩容1.3 线程安全性ArrayList1234567protected transient int modCount = 0;public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;Vector1234567protected transient int modCount = 0;public synchronized void addElement(E obj) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = obj;&#125;Vector add() 方法上增加了 synchronized 关键字，使得 Vector 支持多线程环境下的元素增加删除修改操作。2. 增删改性能对比根据数据结构中知识:顺序表查找元素时间复杂度为 O(1)，适用于随机查找元素的场景。链表增减元素时间复杂度为 O(1)，适用于增减元素比较多的场景。1234567891011121314151617181920212223242526272829303132public static void main(String[] args) &#123; ArrayList arrayList = new ArrayList(); LinkedList linkedList = new LinkedList(); Vector vector = new Vector(); long t1, t2; t1 = System.nanoTime(); for (int i = 0; i &lt; 10000; i++) &#123; arrayList.add(i); &#125; t2 = System.nanoTime(); System.out.println(&quot;ArrayList add:&quot; + (t2 - t1)); t1 = System.nanoTime(); for (int i = 0; i &lt; 10000; i++) &#123; linkedList.add(i); &#125; t2 = System.nanoTime(); System.out.println(&quot;linkedList add:&quot; + (t2 - t1)); t1 = System.nanoTime(); for (int i = 0; i &lt; 10000; i++) &#123; vector.add(i); &#125; t2 = System.nanoTime(); System.out.println(&quot;vector add:&quot; + (t2 - t1));&#125; ArrayList add:6810212linkedList add:3463194vector add:4442985添加元素，ArrayList 花费时间比 LinkList 时间长。1234567891011121314151617181920212223242526272829303132333435363738public static void main(String[] args) &#123; ArrayList arrayList = new ArrayList(); LinkedList linkedList = new LinkedList(); Vector vector = new Vector(); long t1, t2; for (int i = 0; i &lt; 100000; i++) &#123; arrayList.add(i); linkedList.add(i); vector.add(i); &#125; t1 = System.nanoTime(); for (int i = 0; i &lt; 10000; i++) &#123; arrayList.get(i); &#125; t2 = System.nanoTime(); System.out.println(&quot;ArrayList get:&quot; + (t2 - t1)); t1 = System.nanoTime(); for (int i = 0; i &lt; 10000; i++) &#123; linkedList.get(i); &#125; t2 = System.nanoTime(); System.out.println(&quot;linkedList get:&quot; + (t2 - t1)); t1 = System.nanoTime(); for (int i = 0; i &lt; 10000; i++) &#123; vector.get(i); &#125; t2 = System.nanoTime(); System.out.println(&quot;vector get:&quot; + (t2 - t1));&#125; ArrayList get:72482linkedList get:107975370vector get:242634查找元素上，ArrayList 最快3. 总结将 ArrayList、LinkList 和 Vetor 进行了简单对比，总体来说：在查找元素比较频繁的场合，推荐使用 ArrayList；在修改元素比较频繁的场合，推荐使用 LinkList。Vetor 与 ArrayList 类似，区别在于扩容比例、线程安全方面。性能对比测试结果可能存在添加元素 ArrayList 花费时间比 LinkList 多的情况， 这个原因参考：ArrayList vs LinkedList vs Vector 区别","categories":[{"name":"Java 基础","slug":"Java-基础","permalink":"http://suiyia.github.io/categories/Java-基础/"}],"tags":[{"name":"集合","slug":"集合","permalink":"http://suiyia.github.io/tags/集合/"}]},{"title":"Java字符串拼接效率对比","slug":"Java-字符串拼接效率对比","date":"2019-03-17T07:30:00.000Z","updated":"2019-10-14T02:45:46.509Z","comments":true,"path":"2019/03/17/Java-字符串拼接效率对比/","link":"","permalink":"http://suiyia.github.io/2019/03/17/Java-字符串拼接效率对比/","excerpt":"","text":"用 Google photo 搜索关键词「String」，出现了上图，有兴趣的朋友可以试试，感觉发现了新大陆…Java 中有 3 种字符串的拼接方式，了解这三种拼接方式的实现，将有益于提高自己的代码质量。本文主要讲解 String 对象的三种拼接方式，以及它们之间的效率对比。三种方式1234567891011// 方式 1String s = &quot;Hello&quot;;s += &quot;Hello&quot;;// 方式 2StringBuilder stringBuilder = new StringBuilder(&quot;Hello&quot;);stringBuilder.append(&quot;Hello&quot;);// 方式 3StringBuffer stringBuffer = new StringBuffer(&quot;Hello&quot;);stringBuffer.append(&quot;Hello&quot;);自己写个主函数，将上面 3 个方法循环执行 10000 次；执行时间 t1 &gt; t3 &gt; t2，也就是说 StringBuilder.append() 拼接最快，String += 最慢。源码解读StringBuilder.append() 拼接StringBuilder.java123456789public final class StringBuilder extends AbstractStringBuilder implements java.io.Serializable, CharSequence@Overridepublic StringBuilder append(String str) &#123; super.append(str); // 调用父类 append 方法 return this;&#125;AbstractStringBuilder.java123456789public AbstractStringBuilder append(String str) &#123; if (str == null) return appendNull(); int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); // 调用 String 的 getChars 方法 count += len; return this;&#125;String.java123456789101112public void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) &#123; if (srcBegin &lt; 0) &#123; throw new StringIndexOutOfBoundsException(srcBegin); &#125; if (srcEnd &gt; value.length) &#123; throw new StringIndexOutOfBoundsException(srcEnd); &#125; if (srcBegin &gt; srcEnd) &#123; throw new StringIndexOutOfBoundsException(srcEnd - srcBegin); &#125; System.arraycopy(value, srcBegin, dst, dstBegin, srcEnd - srcBegin); // 本地方法&#125;从上面 3 段代码可知，StringBuilder.append 方法调用的是父类 AbstractStringBuilder.append，父类 append 方法调用了 String 的本地方法 System.arraycopy 实现StringBuffer.append() 拼接StringBuilder.java12345678910public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, CharSequence@Overridepublic synchronized StringBuffer append(String str) &#123; toStringCache = null; super.append(str); return this;&#125;StringBuffer.append 方法与 StringBuilder.append 方法类似，不同的是，append 方法加上了 synchronized 锁，说明该方法适用于多线程环境，但是加锁的过程需要耗时，所以执行时间比 StringBuilder.append 慢。String += 拼接对下面代码进行编译，生成的 class 文件使用命令 javap -c Main.class，可以反编译得到图片中的字节码。可以看到 += 实际调用的是 StringBuilder.append() 方法，所以速度会比 StringBuilder 慢。12345public static void main(String[] args) &#123; String s = &quot;Hello&quot;; s = s + &quot; World&quot;; System.out.println(s);&#125;总结所以在需要拼接字符串的场合，尽量适用 StringBuilder.append() 方法，多线程环境下则推荐 StringBuffer.append() 方法，而 String += 拼接方式任何场合都不建议使用。","categories":[{"name":"Java 基础","slug":"Java-基础","permalink":"http://suiyia.github.io/categories/Java-基础/"}],"tags":[{"name":"String","slug":"String","permalink":"http://suiyia.github.io/tags/String/"}]},{"title":"Java中的值传递","slug":"Java-中的值传递","date":"2019-02-18T15:12:00.000Z","updated":"2019-10-14T02:45:46.565Z","comments":true,"path":"2019/02/18/Java-中的值传递/","link":"","permalink":"http://suiyia.github.io/2019/02/18/Java-中的值传递/","excerpt":"","text":"几个重要概念实参、形参形式参数：定义函数名和函数体时候使用的参数，目的用来接收调用该函数时传入的参数实际参数：在调用有参函数时，主调函数与被调函数之间有数据传递关系。实际参数是调用有参方法的时候真正传递的内容。12345678 public void tes(String name)&#123; // 形式参数 name System.out.println(name);&#125;public static void main(String[] args) &#123; Test test = new Test(); test.tes(&quot;caijicoder&quot;); // 实际参数 caijicoder&#125;值类型、引用类型：值类型就是基本数据类型，8 种基本类型除外的数据类型都是引用类型。两种类型分别表示两种内存分配方式。一个值类型数据直接在栈上分配，存储所包含的值，其值就代表数据本身。一个引用类型指向的数据在堆上分配，引用类型的值是这个堆上数据的地址。12int num = 10;String str = &quot;hello&quot;;num 是基本类型（值类型），值就直接保存在变量中。str 是引用类型，变量中保存的只是实际对象的地址（0x10），而不是 Hello 这个字符串。值传递、引用传递：值传递（pass by value）：指在调用函数时，将实参复制一份传递到函数中，形参接收到的内容其实是实参的一个拷贝，函数对形参的修改并不会影响到实参引用传递（pass by reference）：指在调用函数时，将实参的地址直接传递到函数中，在函数中对参数的修改将会影响到实参值传递和引用传递属于函数调用时参数的求值策略（Evaluation Strategy），这是对调用函数时，求值和传值的方式的描述，并不指传递的内容的类型。也就是说，传递内容的类型是值类型还是引用类型（地址），与值传递、引用传递无关，并不能说传入的参数类型是值类型就是值传递。接下来重点！！！对于值传递，无论是值类型还是引用类型，都会在调用栈上创建一个副本：对于值类型而言，这个副本就是整个原始值的复制，对这个副本的操作，不影响原始值的内容。对于引用类型而言，其副本也只是这个引用的复制，指向的仍然是同一个对象。所以对副本的操作，会影响原始值。为什么 Java 只有值传递，但 C# 既有值传递，又有引用传递，这种语言设计有哪些好处？ - Hugo Gu的回答 - 知乎一个实例定义 Person 类123456789101112131415161718192021222324252627282930313233public class Person &#123; private String name; private int age; public Person(String name, int age) &#123; this.name = name; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return &quot;Person&#123;&quot; + &quot;name=&apos;&quot; + name + &apos;\\&apos;&apos; + &quot;, age=&quot; + age + &apos;&#125;&apos;; &#125;&#125;12345678910111213141516171819202122232425262728293031323334353637383940public class Main &#123; private int X = 123; public void updateVlue(int value)&#123; // 传入基本数据类型 value = value + 1; System.out.println(&quot;变量value: &quot;+value); &#125; public void updateObject(Person person)&#123; // 传入引用类型 Person E = person; E.setAge(21); &#125; public void swapObject(Person A,Person B)&#123; // 传入引用类型 Person C = A; A = B; B = C; &#125; public static void main(String[] args) &#123; // 例子 1 Main main = new Main(); int X = 1; main.updateVlue(X); System.out.println(&quot;X 的值：&quot;+X); // X = 1 // 例子 2 Person A = new Person(&quot;张三&quot;,20); main.updateObject(A); System.out.println(&quot;A: &quot;+A.toString()); // A: Person&#123;name=&apos;张三&apos;, age=21&#125; // 例子 3 Person C = new Person(&quot;C&quot;,10); Person D = new Person(&quot;D&quot;,15); main.swapObject(C,D); System.out.println(&quot;C: &quot;+ C.toString()); // C: Person&#123;name=&apos;C&apos;, age=10&#125; System.out.println(&quot;D: &quot;+ D.toString()); // D: Person&#123;name=&apos;D&apos;, age=15&#125; &#125;&#125;例子1：函数传入基本数据类型（值类型参数），由于 value 是 X 的一个副本，对 value 进行操作，并没有改变原来实参的值。例子2：函数传入引用类型参数，改变了原来的值。由于值传递的缘故，传入引用类型的参数时，其值是这个地址的拷贝，指向的仍然是同一个对象，所以发生了改变。这是值传递带来的效果，与传入的对象是值类型或者引用类型没有关系！例子3：函数传入引用类型，如果 Java 是引用传递， 那么 swapObject(Person A,Person B) 中的形参 A，B 接收的就是 C 和 D 的地址，对 A，B 进行交换应该能成功的，事实上 C 和 D 并没有交换，这从反面证明了 Java 不是引用传递。参考Java 到底是值传递还是引用传递？ - Hollis的回答 - 知乎这一次，彻底解决Java的值传递和引用传递","categories":[{"name":"Java 基础","slug":"Java-基础","permalink":"http://suiyia.github.io/categories/Java-基础/"}],"tags":[]},{"title":"Redis 简单介绍与 Jedis 常用操作","slug":"Redis简单介绍与Jedis常用操作","date":"2019-02-18T13:02:00.000Z","updated":"2019-08-10T09:51:13.097Z","comments":true,"path":"2019/02/18/Redis简单介绍与Jedis常用操作/","link":"","permalink":"http://suiyia.github.io/2019/02/18/Redis简单介绍与Jedis常用操作/","excerpt":"","text":"介绍Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。主要对 Redis 中文网 文档内容进行总结，并使用 Jedis 实现一些基本操作。使用 Jedis 实现 Redis 基本操作Jedis 是一个小而精的 Redis 客户端，用 Java 实现strings 操作123456789String result = jedis.set(\"name\",\"chx\"); // 添加 String ，result = \"OK\"result = jedis.mset(\"name\", \"chenhaoxiang\", \"age\", \"20\", \"email\", \"chxpostbox@outlook.com\"); // 同时设置多个键值对 result = \"OK\"Boolean exists = jedis.exists(\"name\"); // 是否存在 key=user 的记录result = jedis.get(\"name\"); // 获取数据，result = \"chx\"Long appendres = jedis.append(\"name\", \" is my name;\"); // 拼接，appendres = 15，拼接后字符串长度Long delres = jedis.del(\"name\"); //删除某个键值对， delres = 1//键对应 value 的自增操作，具备原子性，如果键包含错误类型的值或包含无法表示为整数的字符串，则会返回错误。此操作限于64位有符号整数。ERR value is not an integer or out of range//如果键不存在，则在执行操作之前将其设置为0。如果 age 不存在，操作后 age = 1；Long incrres = jedis.incr(\"age\"); // 用于将键的整数值递增1。 incrres = 21，递增后的值。lists 操作123456Long res1 = jedis.lpush(\"list\",\"1\"); // 头部插入一个元素，res1 = 1res1 = jedis.lpush(\"list\",\"2\"); // res1 = 2res1 = jedis.lpush(\"list\",\"3\"); // res1 = 3 返回该 List 的长度jedis.rpush(\"list\",\"5\"); // 尾部插入元素Long llen = jedis.llen(\"list\"); // List 长度，llen = 4List&lt;String&gt; list3 = jedis.lrange(\"list\",0,-1); // list3 = [3,2,1,5] 按范围取出,第一个是key，第二个是起始位置，第三个是结束位置sets 操作123456789res1 = jedis.sadd(\"set\",\"1\");res1 = jedis.sadd(\"set\",\"2\");res1 = jedis.sadd(\"set\",\"3\"); // 添加Long srem = jedis.srem(\"set\",\"2\"); // 移除某个元素Set&lt;String&gt; set1 = jedis.smembers(\"set\"); // 获取 key=set 的 SetBoolean sismember = jedis.sismember(\"set\",\"1\"); // key=set 的 Set 中是否存在元素 \"1\"String srandmember = jedis.srandmember(\"set\"); // 随机返回一个 set 元素List&lt;String&gt; list4 = jedis.srandmember(\"set\",2); // 随机返回指定个数个元素Long scar = jedis.scard(\"set\"); // set 的元素个数sorted sets 操作( TODO 用到再更新)123jedis.zadd(\"zset\",1,\"1\");jedis.zadd(\"zset\",2.0,\"2\");jedis.zadd(\"zset\",3,\"3\");Hashes 操作12345678910111213141516Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;();map.put(\"name\", \"chx\");map.put(\"age\", \"100\");map.put(\"email\", \"***@outlook.com\");result = jedis.hmset(\"user\", map); // 添加 Map，result = \"OK\"String res = jedis.hget(\"user\",\"age\"); // 获取 Map 指定 key 的 value，只能获取单个 key，res = 100List&lt;String&gt; list = jedis.hmget(\"user\", \"name\", \"age\", \"email\"); // 获取 Map 指定 key 的 value，同时指定多个 key，list = [chx, 100, ***@outlook.com];Long hdel = jedis.hdel(\"user\", \"age\"); //删除 map 中的某个键值，hdel = 1Long hlen = jedis.hlen(\"user\"); // 获取 map 中的键值对个数，hlen = 2Set&lt;String&gt; set = jedis.hkeys(\"user\"); // 返回 map 中的所有 keyIterator&lt;String&gt; iterator = jedis.hkeys(\"user\").iterator(); // 迭代遍历while (iterator.hasNext())&#123; String key = iterator.next(); String value = jedis.hmget(\"user\",key).get(0);&#125;List&lt;String&gt; list2 = jedis.hvals(\"user\"); // 返回 map 中的所有 valueRedis 其它名词expire 过期Redis 允许为每一个 key 设置不同的过期时间，当它们到期时将自动从服务器上删除。主动删除：client 主动访问，发现过期，立即删除被动删除：Redis 定时随机选择一些 key 进行检测，删除过期的 key，如果删除比例高于 25%，则继续选择一些 key 进行删除管道(Pipelining)Redis是一种基于客户端-服务端模型以及请求/响应协议的TCP服务。发送一个命令之后只有等待服务器返回之后才会执行后续命令。管道则可以一次发送多条命令而不必立即等待服务器返回，收到命令之后，服务器会以队列形式回复命令，管道操作比较耗内存，要注意命令的大小。12345Pipeline pipeline = jedis.pipelined();for (int i = 0; i &lt; 100; i++) &#123; pipeline.set(\"1\",\"1\");&#125;pipeline.sync();Redis学习笔记7–Redis管道（pipeline）分布式缓存Redis之Pipeline（管道）事务将一组 Redis 命令放到事务中执行，MULTI 、 EXEC 、 DISCARD 和 WATCH 是 Redis 事务相关的命令。123456String watch = jedis.watch(\"123\");Transaction multi = jedis.multi();multi.set(\"123\",\"123\");List&lt;Object&gt; list1 = multi.exec();multi.discard();jedis.unwatch();multi 用于开启一个事务，exec 执行事务，watch 用于监测事务中 key 的变化，如果 key 被其它客户端改过了，那么整个事务会被取消，discard 用于取消事务总结这个总结主要是了解下 Jedis 常用操作。具体细节学习需要文档、项目结合学习。博客参考：【Redis】Java中使用Jedis操作Redis(Maven导入包)、创建Redis连接池","categories":[{"name":"Redis","slug":"Redis","permalink":"http://suiyia.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://suiyia.github.io/tags/Redis/"}]},{"title":"Java 常用加密算法实现","slug":"Java-常用加密算法实现","date":"2019-01-27T09:23:00.000Z","updated":"2019-10-13T07:23:48.031Z","comments":true,"path":"2019/01/27/Java-常用加密算法实现/","link":"","permalink":"http://suiyia.github.io/2019/01/27/Java-常用加密算法实现/","excerpt":"","text":"[toc]常用加密算法 Java 实现算法种类单向加密对称加密非对称加密1. 单向加密Base64，Base64 编码是从二进制到字符的过程，用 64 个字符来表示任意的二进制数据，常用于在 HTTP 加密，图片编码传输等。Java 8 内置实现1234567891011121314151617181920package com.cn.singleway;import java.io.UnsupportedEncodingException;import java.util.Base64;public class Base64Demo &#123; public static void main(String[] args) &#123; try &#123; // 编码 String encode = Base64.getEncoder().encodeToString(\"testBase64\".getBytes(\"UTF-8\")); System.out.println(encode); // 解码 byte[] decode = Base64.getDecoder().decode(\"dGVzdEJhc2U2NA==\"); System.out.println(new String(decode, \"UTF-8\")); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125;&#125;JDK 1.8 之下，引入第三方 jar 包1234567891011121314151617181920212223242526package com.cn.singleway;import org.apache.commons.codec.binary.Base64;import java.io.UnsupportedEncodingException;public class Base64Demo2 &#123; public static void main(String[] args) &#123; try &#123; String encodeBase64String = Base64.encodeBase64String(\"test\".getBytes(\"UTF-8\")); System.out.println(encodeBase64String); byte[] decodeString = Base64.decodeBase64(encodeBase64String); System.out.println(new String(decodeString,\"UTF-8\")); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125;&#125; &lt;dependency&gt; &lt;groupId&gt;commons-codec&lt;/groupId&gt; &lt;artifactId&gt;commons-codec&lt;/artifactId&gt; &lt;version&gt;1.11&lt;/version&gt; &lt;/dependency&gt;MD5，Message Digest algorithm 5，信息摘要算法，一般用于确保信息的传输完整一致性，校验传输的数据是否被修改，一旦原始信息被修改，生成的 MD5 值将会变得很不同1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.cn.singleway;import java.io.UnsupportedEncodingException;import java.math.BigInteger;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;public class MD5Demo &#123; public static void test1(String s)&#123; try &#123; MessageDigest messageDigest = MessageDigest.getInstance(\"MD5\"); byte[] after = messageDigest.digest(s.getBytes(\"UTF-8\")); StringBuilder stringBuilder = new StringBuilder(); for (int i = 0; i &lt; after.length; i++) &#123; if ((0xff &amp; after[i]) &lt; 0x10) &#123; stringBuilder.append(\"0\" + Integer.toHexString((0xFF &amp; after[i]))); &#125; else &#123; stringBuilder.append(Integer.toHexString(0xFF &amp; after[i])); &#125; &#125; System.out.println(stringBuilder.toString()); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; public static void test2(String s)&#123; try &#123; // 生成一个MD5加密计算摘要 MessageDigest md = MessageDigest.getInstance(\"MD5\"); // 计算md5函数 md.update(s.getBytes()); // digest()最后确定返回md5 hash值，返回值为8为字符串。因为md5 hash值是16位的hex值，实际上就是8位的字符 // BigInteger函数则将8位的字符串转换成16位hex值，用字符串来表示；得到字符串形式的hash值 System.out.println(new BigInteger(1, md.digest()).toString(16)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; String s = \"this is MD5 test demo\"; test1(s); test2(s); &#125;&#125;SHA 家族，是一个密码散列函数家族，是 FIPS 所认证的安全散列算法，和 MD5 类似，都是对文本进行散列，产生一定长度的散列值SHA1 与 SHA212HMACHash Message Authentication Code，散列消息鉴别码，HMAC运算利用哈希算法，以一个密钥和一个消息为输入，生成一个消息摘要作为输出。122. 对称加密对称加密的意思就是信息收发都有相同的一把钥匙，消息的加密解密都用这进行DES，Data Encryption Standard，数据加密标准，速度较快，适用于加密大量数据的场合。DES算法提供CBC, OFB, CFB, ECB四种模式，MAC是基于ECB实现的。AESAdvanced Encryption Standard，高级加密标准，是下一代的加密算法标准，速度快，安全级别高；3. 非对称加密非对称加密算法是一种密钥的保密方法。 非对称加密算法需要两个密钥：公开密钥（publickey）和私有密钥（privatekey）。 公开密钥与私有密钥是一对，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密；如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密。RSA，名称来源于发明这个算法的三个人的姓氏组成，算法大致内容就是对极大整数进行因式分解。这种算法非常可靠，密钥越长，它就越难破解。根据已经披露的文献，目前被破解的最长 RSA密钥是768个二进制位。也就是说，长度超过768位的密钥，还无法破解（至少没人公开宣布）。因此可以认为，1024位的RSA密钥基本安全，2048位的密钥极其安全。http://www.ruanyifeng.com/blog/2013/06/rsa_algorithm_part_one.htmlDSA，Digital Signature Algorithm，数字签名算法，是一种标准的 DSS（数字签名标准）；ECC，Elliptic Curves Cryptography，椭圆曲线密码编码学。一种建立公开密钥加密的算法，基于椭圆曲线数学。ECC的主要优势是在某些情况下它比其他的方法使用更小的密钥——比如RSA加密算法——提供相当的或更高等级的安全。ECC的另一个优势是可以定义群之间的双线性映射，基于Weil对或是Tate对；双线性映射已经在密码学中发现了大量的应用，例如基于身份的加密。不过一个缺点是加密和解密操作的实现比其他机制花费的时间长。Base64MD5 和 SHA 家族12345678910111213141516171819202122232425262728293031323334353637383940public static void main(String[] args) &#123; String content = \"you are my son\"; // 原文 try &#123; byte[] a; MessageDigest messageDigest = MessageDigest.getInstance(\"SHA-1\"); a = messageDigest.digest(content.getBytes()); System.out.println(byte2hex(a)); // 333a9634d8809b5a9e8d280d82553b8fd8d4a911 messageDigest = MessageDigest.getInstance(\"SHA-256\"); a = messageDigest.digest(content.getBytes()); System.out.println(byte2hex(a)); // cdb2c97079d9a1943eea98de4201f5c4f49ecda5af2b364e1c7a5d1ae89688eb messageDigest = MessageDigest.getInstance(\"MD5\"); a = messageDigest.digest(content.getBytes()); System.out.println(byte2hex(a)); // 6fe6b9a8f8bd29f4f4f1368a0619a7ae // 第三方 MD5 算法。需要添加 jar 包 org.apache.commons.codec.digest.DigestUtils String encodeStr=DigestUtils.md5Hex(content); System.out.println(encodeStr); // 6fe6b9a8f8bd29f4f4f1368a0619a7ae &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125;&#125;public static String byte2hex(byte[] b) //二进制转字符串&#123; String hs = \"\"; String stmp = \"\"; for (int n = 0; n &lt; b.length; n++) &#123; stmp = (java.lang.Integer.toHexString(b[n] &amp; 0XFF)); if (stmp.length() == 1) &#123; hs = hs + \"0\" + stmp; &#125; else &#123; hs = hs + stmp; &#125; &#125; return hs;&#125;总结现在的加密算法大部分情况下是为了验证数据的一致性，例如传递一些参数组的时候，简单的会使用 BASE64 或 MD5 进行加密生成一个签名。复杂点就是 BASE64 编码之后再用 对称密钥再加密一次，达到比较不容易被人篡改的目的对于一些支付场景，一般使用 非对称加密算法 实现，这样的场景需要的安全性更高。其它博客参考java加解密之RSA使用","categories":[{"name":"Java 基础","slug":"Java-基础","permalink":"http://suiyia.github.io/categories/Java-基础/"}],"tags":[{"name":"加密算法","slug":"加密算法","permalink":"http://suiyia.github.io/tags/加密算法/"}]},{"title":"展望 2019 ！","slug":"展望-2019","date":"2019-01-02T14:28:00.000Z","updated":"2019-04-07T13:32:54.458Z","comments":true,"path":"2019/01/02/展望-2019/","link":"","permalink":"http://suiyia.github.io/2019/01/02/展望-2019/","excerpt":"","text":"回首 2018，毕业、入职，名校光环不再，浪潮褪去，原来我一直在裸泳。作为已经工作半年的「职场新人」，仍有许多的不足和需要学习的地方。激情是年轻人应该拥有的东西，没有梦想，和咸鱼一样，我不甘心！制定好目标，坚持的执行下去，总会有好的结果。坚持看书，每天花一个小时看书。自己思考、总结，把书中的想法总结出来，提升了思维也锻炼了写作能力。坚持写博客，从公司项目中了解框架，既熟悉了业务，也运用得了框架，这应该是头两年需要技术积累的东西。坚持锻炼，体重控制在 130 斤应该是最完美的体重，向这个目标进军，现在 140 斤。自己需要注意的地方：聆听的方式。别人与自己说话，学会聆听，学会体会别人话中表现的含义，不轻易打断别人，有时候还需要委婉地表达自己的想法。注意社交，一个人闷着屋里，并不会造出什么轮子，随时了解外面发生的事，多个周围的同事交流，结交更多的朋友，体会不同人的想法、见解，开拓自己的视野。唯一愿望：找一个可以一起吃饭、一起看电影、一起出去玩的女朋友。结语：人生就像一场马拉松，起步快的人，往往能提前看到美丽的风景，坚持久的人，必将得到丰厚的硕果，加油 2019 ！","categories":[],"tags":[]}]}